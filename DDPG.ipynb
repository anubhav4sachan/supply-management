{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PsA1N1-MFpBW"
   },
   "outputs": [],
   "source": [
    "# !pip install ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NfFggFk8ICXQ"
   },
   "outputs": [],
   "source": [
    "# !pip install ray[rllib]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HJm7_4-BFUfv",
    "outputId": "249235c5-a442-47cb-fba6-5b2b641c5b42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import pickle\n",
    "import collections\n",
    "\n",
    "import gym\n",
    "from gym.spaces import Box\n",
    "import ray\n",
    "from ray import tune\n",
    "from ray.rllib.utils import try_import_tf\n",
    "\n",
    "import ray.rllib.agents.ddpg as ddpg\n",
    "from ray.tune.logger import pretty_print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jDInxRLbFapD"
   },
   "outputs": [],
   "source": [
    "class Action(object):\n",
    "    \"\"\"\n",
    "    shipping to warehouses and changes in production level\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, no_of_warehouses):\n",
    "        self.production_level = 0  # b(0,t)\n",
    "        self.shippings = np.repeat(0, no_of_warehouses)  # W(j,t)\n",
    "\n",
    "\n",
    "class State(object):\n",
    "    \"\"\"\n",
    "    defining the state of the environment\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, no_of_warehouses, demand_history, eps, t=0):\n",
    "        self.no_of_warehouses = no_of_warehouses  # W\n",
    "        self.demand_history = demand_history\n",
    "        self.factory_stock = 0  # l(0,t)\n",
    "        self.warehouse_stock = np.repeat(0, no_of_warehouses)  # l(j,t)\n",
    "        self.eps = eps\n",
    "        self.t = t\n",
    "\n",
    "    def array_state(self):\n",
    "        return np.concatenate(([self.factory_stock], self.warehouse_stock, np.hstack(self.demand_history), [self.t]))\n",
    "\n",
    "    def stock_only(self):\n",
    "        return np.concatenate(([self.factory_stock], self.warehouse_stock))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "m9iCwjX6GGo7"
   },
   "outputs": [],
   "source": [
    "class Environment(object):\n",
    "    \"\"\"\n",
    "    defining the reward distribution system\n",
    "    and the next state based on the appropriate action and\n",
    "    current state.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, eps=40, W=4, max_demand=5, r_var=2, c=35, p=98):\n",
    "        \"\"\"\n",
    "            Initializing the initial conditions of the system.\n",
    "        \"\"\"\n",
    "        self.eps = eps  # Epochs (transitions)\n",
    "        self.no_of_warehouses = W\n",
    "        self.d_max = max_demand  # maximum demand at warehouse w -> d(j, t)\n",
    "        self.d_var = r_var  # maximum random variation in units in d(j,t) for different warehouses\n",
    "        self.unit_cost = c  # c_0 -> production cost\n",
    "        self.unit_price = p  # p->product price for retailers\n",
    "\n",
    "        ''' storage capacity at the factory, storage capacity at each warehouse, rupees per unit\n",
    "            first index because of factory warehouse followed by distribution warehouses'''\n",
    "        self.storage_capacities = np.fromfunction(lambda j: 10 * (j + 1), (self.no_of_warehouses + 1,), dtype=int)\n",
    "\n",
    "        ''' storage capacity at the factory, storage capacity at each warehouse, rupees per unit\n",
    "            first index because of factory warehouse followed by distribution warehouses'''\n",
    "        self.storage_costs = np.fromfunction(lambda j: 2 * (j + 1), (self.no_of_warehouses + 1,),\n",
    "                                             dtype=int)\n",
    "\n",
    "        # transportation costs for each warehouse, dollars per unit\n",
    "        self.transporation_costs = np.fromfunction(lambda j: 5 * (j + 1), (self.no_of_warehouses,),\n",
    "                                                   dtype=int)\n",
    "        self.penalty_unit_cost = self.unit_price\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, demand_history_len=4):\n",
    "        \"\"\"\n",
    "        :param demand_history_len: defines number of past records to be tracked\n",
    "        \"\"\"\n",
    "        self.t = 0\n",
    "        self.demand_history = collections.deque(maxlen=demand_history_len)\n",
    "\n",
    "        for _ in range(demand_history_len):\n",
    "            self.demand_history.append(np.zeros(self.no_of_warehouses))\n",
    "\n",
    "    def demand(self, t, j):\n",
    "        \"\"\"\n",
    "        :param t: time at which demand is needed\n",
    "        :param j: warehouse for which demand is needed\n",
    "        :return: returns demand at time t for warehouse j\n",
    "        \"\"\"\n",
    "        return np.round(\n",
    "            self.d_max / 2 + self.d_max / 2 * np.sin(2 * np.pi * (t + 2 * j) / self.eps * 2) + np.random.randint(0, self.d_var))\n",
    "\n",
    "    def initial_state(self):\n",
    "        \"\"\"\n",
    "        :return: returns initial state\n",
    "        \"\"\"\n",
    "        return State(no_of_warehouses=self.no_of_warehouses, demand_history=list(self.demand_history), eps=self.eps)\n",
    "\n",
    "    def step(self, state, action):\n",
    "        \"\"\"\n",
    "        :param state: state instance\n",
    "        :param action: action instance\n",
    "        :return: next_state,rewards,completed episodes or not\n",
    "        \"\"\"\n",
    "        demands = np.fromfunction(lambda j: self.demand(self.t, j + 1), (self.no_of_warehouses,), dtype=int)\n",
    "\n",
    "        # calculating the reward (profit)\n",
    "        total_revenue = self.unit_price * np.sum(demands)\n",
    "        production_cost = self.unit_cost * action.production_level\n",
    "        total_storage_cost = np.dot(self.storage_costs,\n",
    "                                    np.maximum(state.stock_only(), np.zeros(self.no_of_warehouses + 1)))\n",
    "\n",
    "        transportation_cost = np.dot(self.transporation_costs, action.shippings)\n",
    "        penalty_cost = -1 * self.penalty_unit_cost * (\n",
    "                np.sum(np.minimum(state.warehouse_stock, np.zeros(self.no_of_warehouses))) + min(\n",
    "            state.factory_stock, 0))\n",
    "\n",
    "        rewards = total_revenue - production_cost - total_storage_cost - penalty_cost - transportation_cost\n",
    "\n",
    "        # Calculating next state\n",
    "        next_state = State(no_of_warehouses=self.no_of_warehouses, demand_history=list(self.demand_history),\n",
    "                           eps=self.eps,\n",
    "                           t=self.t)\n",
    "        next_state.factory_stock = min(state.factory_stock + action.production_level - np.sum(action.shippings),\n",
    "                                       self.storage_capacities[0])\n",
    "\n",
    "        for i in range(self.no_of_warehouses):\n",
    "            next_state.warehouse_stock[i] = min(\n",
    "                state.warehouse_stock[i] + action.shippings[i] - demands[i],\n",
    "                self.storage_capacities[i + 1])\n",
    "\n",
    "        self.t += 1\n",
    "        self.demand_history.append(demands)\n",
    "        return next_state, rewards, self.t == self.eps - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "3zXMluMjGUV6"
   },
   "outputs": [],
   "source": [
    "tf = try_import_tf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "clongn3PGlmp"
   },
   "outputs": [],
   "source": [
    "class SimpleChain(gym.Env):\n",
    "    def __init__(self, config):\n",
    "        self.reset()\n",
    "        self.action_space = Box(low=0.0, high=20.0, shape=(self.chain.no_of_warehouses + 1,),\n",
    "                                dtype=np.float32)\n",
    "        self.observation_space = Box(-10000, 10000,\n",
    "                                     shape=(len(self.chain.initial_state().array_state()),),\n",
    "                                     dtype=np.float32)\n",
    "\n",
    "    def reset(self):\n",
    "        self.chain = Environment()\n",
    "        self.state = self.chain.initial_state()\n",
    "        return self.state.array_state()\n",
    "\n",
    "    def step(self, action):\n",
    "        action_obj = Action(self.chain.no_of_warehouses)\n",
    "        action_obj.production_level = action[0]\n",
    "        action_obj.shippings = action[1:]\n",
    "        self.state, reward, term_sig = self.chain.step(self.state, action_obj)\n",
    "        return self.state.array_state(), reward, term_sig, {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWQaBbAFG7Se",
    "outputId": "be92a8fe-f944-4608-c739-3c0ecd7f2647"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 18:16:24,133\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'metrics_export_port': 35050,\n",
       " 'node_ip_address': '172.28.0.2',\n",
       " 'object_store_address': '/tmp/ray/session_2020-11-05_18-16-23_585106_370/sockets/plasma_store',\n",
       " 'raylet_ip_address': '172.28.0.2',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-11-05_18-16-23_585106_370/sockets/raylet',\n",
       " 'redis_address': '172.28.0.2:6379',\n",
       " 'session_dir': '/tmp/ray/session_2020-11-05_18-16-23_585106_370',\n",
       " 'webui_url': '127.0.0.1:8265'}"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "R8cFHqzQG-Ss"
   },
   "outputs": [],
   "source": [
    "def train_ddpg():\n",
    "    config = ddpg.DEFAULT_CONFIG.copy()\n",
    "    config[\"log_level\"] = \"WARN\"\n",
    "    config[\"actor_hiddens\"] = [512, 512]\n",
    "    config[\"critic_hiddens\"] = [512, 512]\n",
    "    config[\"gamma\"] = 0.95\n",
    "    config[\"timesteps_per_iteration\"] = 1000\n",
    "    config[\"target_network_update_freq\"] = 5\n",
    "    config[\"buffer_size\"] = 10000\n",
    "    \n",
    "    trainer = ddpg.DDPGTrainer(config=config, env=SimpleChain)\n",
    "    for i in range(300):\n",
    "        result = trainer.train()\n",
    "        print(pretty_print(result))\n",
    "        checkpoint = trainer.save()\n",
    "        print(\"Checkpoint saved at\", checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KvGWQwM1HP_x",
    "outputId": "a9ade702-6f97-4c81-ac99-bcadaea9b5d4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-11-05 18:16:26,547\tINFO trainer.py:591 -- Tip: set framework=tfe or the --eager flag to enable TensorFlow eager execution\n",
      "2020-11-05 18:16:26,548\tINFO trainer.py:618 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags.\n",
      "2020-11-05 18:16:28,989\tWARNING util.py:39 -- Install gputil for GPU system monitoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "date: 2020-11-05_19-52-20\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7855.318004757166\n",
      "episode_reward_mean: 4114.451913265446\n",
      "episode_reward_min: -884.1606440991163\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8060\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 201498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3945.188720703125\n",
      "      mean_q: 1579.9464111328125\n",
      "      min_q: -1959.6827392578125\n",
      "      model: {}\n",
      "  num_steps_sampled: 201500\n",
      "  num_steps_trained: 51200256\n",
      "  num_target_updates: 33334\n",
      "iterations_since_restore: 201\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4875\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09384878515905867\n",
      "  mean_env_wait_ms: 0.25736872099868896\n",
      "  mean_inference_ms: 2.038485096606735\n",
      "  mean_raw_obs_processing_ms: 0.23111849821898886\n",
      "time_since_restore: 5745.908595561981\n",
      "time_this_iter_s: 28.49080753326416\n",
      "time_total_s: 5745.908595561981\n",
      "timers:\n",
      "  learn_throughput: 75185.16\n",
      "  learn_time_ms: 3.405\n",
      "timestamp: 1604605940\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 201500\n",
      "training_iteration: 201\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_201/checkpoint-201\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-52-48\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7855.318004757166\n",
      "episode_reward_mean: 4518.566453312849\n",
      "episode_reward_min: -48.80584790557623\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8100\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 202500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4347.40478515625\n",
      "      mean_q: 1745.3155517578125\n",
      "      min_q: -1711.3250732421875\n",
      "      model: {}\n",
      "  num_steps_sampled: 202500\n",
      "  num_steps_trained: 51456256\n",
      "  num_target_updates: 33501\n",
      "iterations_since_restore: 202\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.429268292682934\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09386592803285984\n",
      "  mean_env_wait_ms: 0.2573853622232742\n",
      "  mean_inference_ms: 2.038578741973262\n",
      "  mean_raw_obs_processing_ms: 0.23113237383517776\n",
      "time_since_restore: 5774.843530654907\n",
      "time_this_iter_s: 28.934935092926025\n",
      "time_total_s: 5774.843530654907\n",
      "timers:\n",
      "  learn_throughput: 75728.681\n",
      "  learn_time_ms: 3.38\n",
      "timestamp: 1604605968\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 202500\n",
      "training_iteration: 202\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_202/checkpoint-202\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-53-18\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7855.318004757166\n",
      "episode_reward_mean: 4663.753689097017\n",
      "episode_reward_min: 284.7473377287388\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8140\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 203496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4203.10693359375\n",
      "      mean_q: 1971.717529296875\n",
      "      min_q: -674.950927734375\n",
      "      model: {}\n",
      "  num_steps_sampled: 203500\n",
      "  num_steps_trained: 51712256\n",
      "  num_target_updates: 33667\n",
      "iterations_since_restore: 203\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.47857142857143\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09388543352156303\n",
      "  mean_env_wait_ms: 0.25741679234420334\n",
      "  mean_inference_ms: 2.038707305971746\n",
      "  mean_raw_obs_processing_ms: 0.23116611352136424\n",
      "time_since_restore: 5804.164923429489\n",
      "time_this_iter_s: 29.32139277458191\n",
      "time_total_s: 5804.164923429489\n",
      "timers:\n",
      "  learn_throughput: 64829.695\n",
      "  learn_time_ms: 3.949\n",
      "timestamp: 1604605998\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 203500\n",
      "training_iteration: 203\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_203/checkpoint-203\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-53-47\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7047.93430660665\n",
      "episode_reward_mean: 4926.286097934898\n",
      "episode_reward_min: 284.7473377287388\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8180\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 204498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3769.95654296875\n",
      "      mean_q: 1817.027587890625\n",
      "      min_q: -1402.4425048828125\n",
      "      model: {}\n",
      "  num_steps_sampled: 204500\n",
      "  num_steps_trained: 51968256\n",
      "  num_target_updates: 33834\n",
      "iterations_since_restore: 204\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.56585365853658\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09390076042714159\n",
      "  mean_env_wait_ms: 0.2574499578024628\n",
      "  mean_inference_ms: 2.038757524710948\n",
      "  mean_raw_obs_processing_ms: 0.2312037087676926\n",
      "time_since_restore: 5833.261391401291\n",
      "time_this_iter_s: 29.096467971801758\n",
      "time_total_s: 5833.261391401291\n",
      "timers:\n",
      "  learn_throughput: 72099.985\n",
      "  learn_time_ms: 3.551\n",
      "timestamp: 1604606027\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 204500\n",
      "training_iteration: 204\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_204/checkpoint-204\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-54-15\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7047.93430660665\n",
      "episode_reward_mean: 4930.12799927528\n",
      "episode_reward_min: 140.6553177461028\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8220\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 205500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4103.1748046875\n",
      "      mean_q: 1860.6807861328125\n",
      "      min_q: -724.973876953125\n",
      "      model: {}\n",
      "  num_steps_sampled: 205500\n",
      "  num_steps_trained: 52224256\n",
      "  num_target_updates: 34001\n",
      "iterations_since_restore: 205\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.52439024390244\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391401086392592\n",
      "  mean_env_wait_ms: 0.2574691372430155\n",
      "  mean_inference_ms: 2.038812114482507\n",
      "  mean_raw_obs_processing_ms: 0.2312264051678683\n",
      "time_since_restore: 5861.723663568497\n",
      "time_this_iter_s: 28.46227216720581\n",
      "time_total_s: 5861.723663568497\n",
      "timers:\n",
      "  learn_throughput: 75921.983\n",
      "  learn_time_ms: 3.372\n",
      "timestamp: 1604606055\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 205500\n",
      "training_iteration: 205\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_205/checkpoint-205\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-54-44\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 6982.671045586467\n",
      "episode_reward_mean: 4862.06120246984\n",
      "episode_reward_min: 140.6553177461028\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8260\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 206496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3840.321533203125\n",
      "      mean_q: 1864.929931640625\n",
      "      min_q: -1647.803466796875\n",
      "      model: {}\n",
      "  num_steps_sampled: 206500\n",
      "  num_steps_trained: 52480256\n",
      "  num_target_updates: 34167\n",
      "iterations_since_restore: 206\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.3775\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392228256103649\n",
      "  mean_env_wait_ms: 0.2574670221103903\n",
      "  mean_inference_ms: 2.0388475916765434\n",
      "  mean_raw_obs_processing_ms: 0.23122153426509698\n",
      "time_since_restore: 5890.028209209442\n",
      "time_this_iter_s: 28.304545640945435\n",
      "time_total_s: 5890.028209209442\n",
      "timers:\n",
      "  learn_throughput: 72691.085\n",
      "  learn_time_ms: 3.522\n",
      "timestamp: 1604606084\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 206500\n",
      "training_iteration: 206\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_206/checkpoint-206\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-55-13\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7331.841282308102\n",
      "episode_reward_mean: 4664.373547634743\n",
      "episode_reward_min: -116.5183187276125\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8300\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 207498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4151.07470703125\n",
      "      mean_q: 1829.220947265625\n",
      "      min_q: -734.6986694335938\n",
      "      model: {}\n",
      "  num_steps_sampled: 207500\n",
      "  num_steps_trained: 52736256\n",
      "  num_target_updates: 34334\n",
      "iterations_since_restore: 207\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.380487804878044\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939244075657961\n",
      "  mean_env_wait_ms: 0.2574558030005866\n",
      "  mean_inference_ms: 2.0387714149068557\n",
      "  mean_raw_obs_processing_ms: 0.2312100588981879\n",
      "time_since_restore: 5919.207856655121\n",
      "time_this_iter_s: 29.17964744567871\n",
      "time_total_s: 5919.207856655121\n",
      "timers:\n",
      "  learn_throughput: 72353.595\n",
      "  learn_time_ms: 3.538\n",
      "timestamp: 1604606113\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 207500\n",
      "training_iteration: 207\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_207/checkpoint-207\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-55-42\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7331.841282308102\n",
      "episode_reward_mean: 4862.151457483507\n",
      "episode_reward_min: -116.5183187276125\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8340\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 208500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4060.637939453125\n",
      "      mean_q: 1901.78076171875\n",
      "      min_q: -1765.357421875\n",
      "      model: {}\n",
      "  num_steps_sampled: 208500\n",
      "  num_steps_trained: 52992256\n",
      "  num_target_updates: 34501\n",
      "iterations_since_restore: 208\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.52439024390244\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392415978815055\n",
      "  mean_env_wait_ms: 0.2574428730226024\n",
      "  mean_inference_ms: 2.038615627836994\n",
      "  mean_raw_obs_processing_ms: 0.23120952353931035\n",
      "time_since_restore: 5947.899711847305\n",
      "time_this_iter_s: 28.69185519218445\n",
      "time_total_s: 5947.899711847305\n",
      "timers:\n",
      "  learn_throughput: 70744.699\n",
      "  learn_time_ms: 3.619\n",
      "timestamp: 1604606142\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 208500\n",
      "training_iteration: 208\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_208/checkpoint-208\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-56-10\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7411.744888469577\n",
      "episode_reward_mean: 4741.823798320704\n",
      "episode_reward_min: -20362.644754707813\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8380\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 209496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4301.5380859375\n",
      "      mean_q: 1972.1363525390625\n",
      "      min_q: -1757.01611328125\n",
      "      model: {}\n",
      "  num_steps_sampled: 209500\n",
      "  num_steps_trained: 53248256\n",
      "  num_target_updates: 34667\n",
      "iterations_since_restore: 209\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.592499999999994\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392569310211658\n",
      "  mean_env_wait_ms: 0.2574242847189274\n",
      "  mean_inference_ms: 2.038500417280934\n",
      "  mean_raw_obs_processing_ms: 0.23120670489886666\n",
      "time_since_restore: 5976.128750085831\n",
      "time_this_iter_s: 28.22903823852539\n",
      "time_total_s: 5976.128750085831\n",
      "timers:\n",
      "  learn_throughput: 73729.294\n",
      "  learn_time_ms: 3.472\n",
      "timestamp: 1604606170\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 209500\n",
      "training_iteration: 209\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_209/checkpoint-209\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-56-38\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7448.256486274302\n",
      "episode_reward_mean: 4246.104036317887\n",
      "episode_reward_min: -20762.609916329384\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8420\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 210498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4364.87548828125\n",
      "      mean_q: 1977.32470703125\n",
      "      min_q: -3813.283203125\n",
      "      model: {}\n",
      "  num_steps_sampled: 210500\n",
      "  num_steps_trained: 53504256\n",
      "  num_target_updates: 34834\n",
      "iterations_since_restore: 210\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.459999999999994\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392485308727419\n",
      "  mean_env_wait_ms: 0.2573958470744016\n",
      "  mean_inference_ms: 2.0384019307417374\n",
      "  mean_raw_obs_processing_ms: 0.23119211275262472\n",
      "time_since_restore: 6004.3356256484985\n",
      "time_this_iter_s: 28.206875562667847\n",
      "time_total_s: 6004.3356256484985\n",
      "timers:\n",
      "  learn_throughput: 74074.66\n",
      "  learn_time_ms: 3.456\n",
      "timestamp: 1604606198\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 210500\n",
      "training_iteration: 210\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_210/checkpoint-210\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-57-08\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7554.726933889091\n",
      "episode_reward_mean: 4410.6999292215705\n",
      "episode_reward_min: -20762.609916329384\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8460\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 211500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3915.207763671875\n",
      "      mean_q: 2031.344482421875\n",
      "      min_q: -1565.2969970703125\n",
      "      model: {}\n",
      "  num_steps_sampled: 211500\n",
      "  num_steps_trained: 53760256\n",
      "  num_target_updates: 35001\n",
      "iterations_since_restore: 211\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.45238095238095\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392861011198031\n",
      "  mean_env_wait_ms: 0.2573834787897284\n",
      "  mean_inference_ms: 2.0382893045731687\n",
      "  mean_raw_obs_processing_ms: 0.23119486702689265\n",
      "time_since_restore: 6033.631251811981\n",
      "time_this_iter_s: 29.295626163482666\n",
      "time_total_s: 6033.631251811981\n",
      "timers:\n",
      "  learn_throughput: 75241.006\n",
      "  learn_time_ms: 3.402\n",
      "timestamp: 1604606228\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 211500\n",
      "training_iteration: 211\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_211/checkpoint-211\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-57-36\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7554.726933889091\n",
      "episode_reward_mean: 4535.600320554618\n",
      "episode_reward_min: -20762.609916329384\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8500\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 212496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4023.866455078125\n",
      "      mean_q: 1981.3089599609375\n",
      "      min_q: -11908.9462890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 212500\n",
      "  num_steps_trained: 54016256\n",
      "  num_target_updates: 35167\n",
      "iterations_since_restore: 212\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.40975609756098\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393646399770074\n",
      "  mean_env_wait_ms: 0.25738007719456535\n",
      "  mean_inference_ms: 2.0382063285683496\n",
      "  mean_raw_obs_processing_ms: 0.2312071590584383\n",
      "time_since_restore: 6062.312344789505\n",
      "time_this_iter_s: 28.681092977523804\n",
      "time_total_s: 6062.312344789505\n",
      "timers:\n",
      "  learn_throughput: 69360.03\n",
      "  learn_time_ms: 3.691\n",
      "timestamp: 1604606256\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 212500\n",
      "training_iteration: 212\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_212/checkpoint-212\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-58-05\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7333.9226555116475\n",
      "episode_reward_mean: 4910.845081820144\n",
      "episode_reward_min: 1361.093909457326\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8540\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 213498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4098.14501953125\n",
      "      mean_q: 1841.3026123046875\n",
      "      min_q: -15907.3388671875\n",
      "      model: {}\n",
      "  num_steps_sampled: 213500\n",
      "  num_steps_trained: 54272256\n",
      "  num_target_updates: 35334\n",
      "iterations_since_restore: 213\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.397499999999994\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394432298258998\n",
      "  mean_env_wait_ms: 0.2573745166171461\n",
      "  mean_inference_ms: 2.0381540146018597\n",
      "  mean_raw_obs_processing_ms: 0.23121470429599822\n",
      "time_since_restore: 6091.029329299927\n",
      "time_this_iter_s: 28.716984510421753\n",
      "time_total_s: 6091.029329299927\n",
      "timers:\n",
      "  learn_throughput: 73763.229\n",
      "  learn_time_ms: 3.471\n",
      "timestamp: 1604606285\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 213500\n",
      "training_iteration: 213\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_213/checkpoint-213\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-58-33\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7916.0831080675125\n",
      "episode_reward_mean: 5135.403755749939\n",
      "episode_reward_min: 1718.929498238489\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8580\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 214500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4224.724609375\n",
      "      mean_q: 2223.439453125\n",
      "      min_q: -6138.095703125\n",
      "      model: {}\n",
      "  num_steps_sampled: 214500\n",
      "  num_steps_trained: 54528256\n",
      "  num_target_updates: 35501\n",
      "iterations_since_restore: 214\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.44634146341464\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394568180478081\n",
      "  mean_env_wait_ms: 0.25735475844697847\n",
      "  mean_inference_ms: 2.038109993180324\n",
      "  mean_raw_obs_processing_ms: 0.23120632653788553\n",
      "time_since_restore: 6119.304786205292\n",
      "time_this_iter_s: 28.27545690536499\n",
      "time_total_s: 6119.304786205292\n",
      "timers:\n",
      "  learn_throughput: 76246.535\n",
      "  learn_time_ms: 3.358\n",
      "timestamp: 1604606313\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 214500\n",
      "training_iteration: 214\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_214/checkpoint-214\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-59-02\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7916.0831080675125\n",
      "episode_reward_mean: 5437.283441267381\n",
      "episode_reward_min: 1811.2402954623103\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8620\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 215496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4169.05615234375\n",
      "      mean_q: 2247.162353515625\n",
      "      min_q: -1198.8758544921875\n",
      "      model: {}\n",
      "  num_steps_sampled: 215500\n",
      "  num_steps_trained: 54784256\n",
      "  num_target_updates: 35667\n",
      "iterations_since_restore: 215\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.39512195121951\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394501268494895\n",
      "  mean_env_wait_ms: 0.25734707531719714\n",
      "  mean_inference_ms: 2.0380382973336952\n",
      "  mean_raw_obs_processing_ms: 0.23120174102214883\n",
      "time_since_restore: 6148.4958119392395\n",
      "time_this_iter_s: 29.191025733947754\n",
      "time_total_s: 6148.4958119392395\n",
      "timers:\n",
      "  learn_throughput: 75277.931\n",
      "  learn_time_ms: 3.401\n",
      "timestamp: 1604606342\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 215500\n",
      "training_iteration: 215\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_215/checkpoint-215\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_19-59-31\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7916.0831080675125\n",
      "episode_reward_mean: 5673.045706969479\n",
      "episode_reward_min: 1811.2402954623103\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8660\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 216498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4145.33203125\n",
      "      mean_q: 2183.953369140625\n",
      "      min_q: -2838.623779296875\n",
      "      model: {}\n",
      "  num_steps_sampled: 216500\n",
      "  num_steps_trained: 55040256\n",
      "  num_target_updates: 35834\n",
      "iterations_since_restore: 216\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.39999999999999\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394398514873493\n",
      "  mean_env_wait_ms: 0.2573404766057729\n",
      "  mean_inference_ms: 2.0379456454979628\n",
      "  mean_raw_obs_processing_ms: 0.2311987860140153\n",
      "time_since_restore: 6177.278787136078\n",
      "time_this_iter_s: 28.78297519683838\n",
      "time_total_s: 6177.278787136078\n",
      "timers:\n",
      "  learn_throughput: 76270.907\n",
      "  learn_time_ms: 3.356\n",
      "timestamp: 1604606371\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 216500\n",
      "training_iteration: 216\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_216/checkpoint-216\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-00-00\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7458.209435045719\n",
      "episode_reward_mean: 5464.150227612167\n",
      "episode_reward_min: 573.5904667377472\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8700\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 217500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4167.97900390625\n",
      "      mean_q: 2126.525390625\n",
      "      min_q: -1987.354248046875\n",
      "      model: {}\n",
      "  num_steps_sampled: 217500\n",
      "  num_steps_trained: 55296256\n",
      "  num_target_updates: 36001\n",
      "iterations_since_restore: 217\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.43414634146342\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939463926838885\n",
      "  mean_env_wait_ms: 0.2573378701195418\n",
      "  mean_inference_ms: 2.037869856384975\n",
      "  mean_raw_obs_processing_ms: 0.2311991643142041\n",
      "time_since_restore: 6206.058524131775\n",
      "time_this_iter_s: 28.77973699569702\n",
      "time_total_s: 6206.058524131775\n",
      "timers:\n",
      "  learn_throughput: 73335.507\n",
      "  learn_time_ms: 3.491\n",
      "timestamp: 1604606400\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 217500\n",
      "training_iteration: 217\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_217/checkpoint-217\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-00-28\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7458.209435045719\n",
      "episode_reward_mean: 5238.0776579858875\n",
      "episode_reward_min: -733.9622460752726\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8740\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 218496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3970.7919921875\n",
      "      mean_q: 2149.14599609375\n",
      "      min_q: -2866.801513671875\n",
      "      model: {}\n",
      "  num_steps_sampled: 218500\n",
      "  num_steps_trained: 55552256\n",
      "  num_target_updates: 36167\n",
      "iterations_since_restore: 218\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.49000000000001\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394727409828173\n",
      "  mean_env_wait_ms: 0.25732445716061275\n",
      "  mean_inference_ms: 2.037839913827642\n",
      "  mean_raw_obs_processing_ms: 0.23119026211589108\n",
      "time_since_restore: 6234.303066730499\n",
      "time_this_iter_s: 28.244542598724365\n",
      "time_total_s: 6234.303066730499\n",
      "timers:\n",
      "  learn_throughput: 74816.351\n",
      "  learn_time_ms: 3.422\n",
      "timestamp: 1604606428\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 218500\n",
      "training_iteration: 218\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_218/checkpoint-218\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-00-58\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7520.136290885508\n",
      "episode_reward_mean: 5338.355321623696\n",
      "episode_reward_min: -733.9622460752726\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8780\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 219498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4249.830078125\n",
      "      mean_q: 2240.239013671875\n",
      "      min_q: -1214.3299560546875\n",
      "      model: {}\n",
      "  num_steps_sampled: 219500\n",
      "  num_steps_trained: 55808256\n",
      "  num_target_updates: 36334\n",
      "iterations_since_restore: 219\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.47317073170732\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394787169987115\n",
      "  mean_env_wait_ms: 0.25731615121124135\n",
      "  mean_inference_ms: 2.037805815113411\n",
      "  mean_raw_obs_processing_ms: 0.23118549939361693\n",
      "time_since_restore: 6263.521052598953\n",
      "time_this_iter_s: 29.21798586845398\n",
      "time_total_s: 6263.521052598953\n",
      "timers:\n",
      "  learn_throughput: 78184.135\n",
      "  learn_time_ms: 3.274\n",
      "timestamp: 1604606458\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 219500\n",
      "training_iteration: 219\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_219/checkpoint-219\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-01-26\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 7996.12163573131\n",
      "episode_reward_mean: 6002.632532971998\n",
      "episode_reward_min: 1648.823627024889\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8820\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 220500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4103.958984375\n",
      "      mean_q: 2213.4599609375\n",
      "      min_q: -737.7750244140625\n",
      "      model: {}\n",
      "  num_steps_sampled: 220500\n",
      "  num_steps_trained: 56064256\n",
      "  num_target_updates: 36501\n",
      "iterations_since_restore: 220\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.363414634146345\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394593873615387\n",
      "  mean_env_wait_ms: 0.257302322818521\n",
      "  mean_inference_ms: 2.037766001716232\n",
      "  mean_raw_obs_processing_ms: 0.23117794070571784\n",
      "time_since_restore: 6292.06582069397\n",
      "time_this_iter_s: 28.54476809501648\n",
      "time_total_s: 6292.06582069397\n",
      "timers:\n",
      "  learn_throughput: 76523.666\n",
      "  learn_time_ms: 3.345\n",
      "timestamp: 1604606486\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 220500\n",
      "training_iteration: 220\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_220/checkpoint-220\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-01-55\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 8320.511056944728\n",
      "episode_reward_mean: 6620.648550145643\n",
      "episode_reward_min: 2537.145921975374\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8860\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 221496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4030.169921875\n",
      "      mean_q: 2273.2392578125\n",
      "      min_q: -318.06884765625\n",
      "      model: {}\n",
      "  num_steps_sampled: 221500\n",
      "  num_steps_trained: 56320256\n",
      "  num_target_updates: 36667\n",
      "iterations_since_restore: 221\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.529268292682936\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394396480130164\n",
      "  mean_env_wait_ms: 0.2572858341812127\n",
      "  mean_inference_ms: 2.0377225496396454\n",
      "  mean_raw_obs_processing_ms: 0.23117052029407203\n",
      "time_since_restore: 6320.630329608917\n",
      "time_this_iter_s: 28.56450891494751\n",
      "time_total_s: 6320.630329608917\n",
      "timers:\n",
      "  learn_throughput: 76440.86\n",
      "  learn_time_ms: 3.349\n",
      "timestamp: 1604606515\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 221500\n",
      "training_iteration: 221\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_221/checkpoint-221\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-02-23\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 8372.804424077272\n",
      "episode_reward_mean: 6937.570522209355\n",
      "episode_reward_min: 2537.145921975374\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8900\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 222498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4083.769775390625\n",
      "      mean_q: 2409.06103515625\n",
      "      min_q: -217.751953125\n",
      "      model: {}\n",
      "  num_steps_sampled: 222500\n",
      "  num_steps_trained: 56576256\n",
      "  num_target_updates: 36834\n",
      "iterations_since_restore: 222\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.489999999999995\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394123054439936\n",
      "  mean_env_wait_ms: 0.2572671633818666\n",
      "  mean_inference_ms: 2.0376999282518518\n",
      "  mean_raw_obs_processing_ms: 0.23116156012359895\n",
      "time_since_restore: 6349.114909648895\n",
      "time_this_iter_s: 28.484580039978027\n",
      "time_total_s: 6349.114909648895\n",
      "timers:\n",
      "  learn_throughput: 76541.122\n",
      "  learn_time_ms: 3.345\n",
      "timestamp: 1604606543\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 222500\n",
      "training_iteration: 222\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_222/checkpoint-222\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-02-53\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9219.767125278711\n",
      "episode_reward_mean: 6971.173887625155\n",
      "episode_reward_min: 2537.145921975374\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8940\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 223500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4127.1728515625\n",
      "      mean_q: 2486.252685546875\n",
      "      min_q: 176.7649688720703\n",
      "      model: {}\n",
      "  num_steps_sampled: 223500\n",
      "  num_steps_trained: 56832256\n",
      "  num_target_updates: 37001\n",
      "iterations_since_restore: 223\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.33809523809524\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939476939062868\n",
      "  mean_env_wait_ms: 0.25726869475214015\n",
      "  mean_inference_ms: 2.037718275996322\n",
      "  mean_raw_obs_processing_ms: 0.23117069478929408\n",
      "time_since_restore: 6378.604405641556\n",
      "time_this_iter_s: 29.489495992660522\n",
      "time_total_s: 6378.604405641556\n",
      "timers:\n",
      "  learn_throughput: 68280.298\n",
      "  learn_time_ms: 3.749\n",
      "timestamp: 1604606573\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 223500\n",
      "training_iteration: 223\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_223/checkpoint-223\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-03-22\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9219.767125278711\n",
      "episode_reward_mean: 7132.559149451409\n",
      "episode_reward_min: 4987.027657968923\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 8980\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 224496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3677.65771484375\n",
      "      mean_q: 2388.63232421875\n",
      "      min_q: 148.80300903320312\n",
      "      model: {}\n",
      "  num_steps_sampled: 224500\n",
      "  num_steps_trained: 57088256\n",
      "  num_target_updates: 37167\n",
      "iterations_since_restore: 224\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.49756097560977\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395466397908994\n",
      "  mean_env_wait_ms: 0.2572727950948773\n",
      "  mean_inference_ms: 2.0377220848229416\n",
      "  mean_raw_obs_processing_ms: 0.23118514272866775\n",
      "time_since_restore: 6407.50568652153\n",
      "time_this_iter_s: 28.901280879974365\n",
      "time_total_s: 6407.50568652153\n",
      "timers:\n",
      "  learn_throughput: 76777.558\n",
      "  learn_time_ms: 3.334\n",
      "timestamp: 1604606602\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 224500\n",
      "training_iteration: 224\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_224/checkpoint-224\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-03-50\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9219.767125278711\n",
      "episode_reward_mean: 7049.562509514617\n",
      "episode_reward_min: 4081.910605624318\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9020\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 225498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4116.4072265625\n",
      "      mean_q: 2565.83984375\n",
      "      min_q: 301.6590881347656\n",
      "      model: {}\n",
      "  num_steps_sampled: 225500\n",
      "  num_steps_trained: 57344256\n",
      "  num_target_updates: 37334\n",
      "iterations_since_restore: 225\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.475\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395542587571251\n",
      "  mean_env_wait_ms: 0.25726387561703673\n",
      "  mean_inference_ms: 2.037652114284173\n",
      "  mean_raw_obs_processing_ms: 0.2311852714407406\n",
      "time_since_restore: 6435.98614358902\n",
      "time_this_iter_s: 28.480457067489624\n",
      "time_total_s: 6435.98614358902\n",
      "timers:\n",
      "  learn_throughput: 74037.885\n",
      "  learn_time_ms: 3.458\n",
      "timestamp: 1604606630\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 225500\n",
      "training_iteration: 225\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_225/checkpoint-225\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-04-19\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 8805.953036636114\n",
      "episode_reward_mean: 7067.655408181311\n",
      "episode_reward_min: 4081.910605624318\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9060\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 226500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3963.379150390625\n",
      "      mean_q: 2652.103271484375\n",
      "      min_q: -241.65335083007812\n",
      "      model: {}\n",
      "  num_steps_sampled: 226500\n",
      "  num_steps_trained: 57600256\n",
      "  num_target_updates: 37501\n",
      "iterations_since_restore: 226\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.53170731707316\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395193306287325\n",
      "  mean_env_wait_ms: 0.25724685169826805\n",
      "  mean_inference_ms: 2.037639574372913\n",
      "  mean_raw_obs_processing_ms: 0.23117412704165305\n",
      "time_since_restore: 6464.3552412986755\n",
      "time_this_iter_s: 28.36909770965576\n",
      "time_total_s: 6464.3552412986755\n",
      "timers:\n",
      "  learn_throughput: 69644.805\n",
      "  learn_time_ms: 3.676\n",
      "timestamp: 1604606659\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 226500\n",
      "training_iteration: 226\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_226/checkpoint-226\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-04-48\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 8805.953036636114\n",
      "episode_reward_mean: 7253.7036544033235\n",
      "episode_reward_min: 3890.1749329715967\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9100\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 227496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3990.092041015625\n",
      "      mean_q: 2712.5166015625\n",
      "      min_q: 509.2978515625\n",
      "      model: {}\n",
      "  num_steps_sampled: 227500\n",
      "  num_steps_trained: 57856256\n",
      "  num_target_updates: 37667\n",
      "iterations_since_restore: 227\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.37073170731708\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394919734992085\n",
      "  mean_env_wait_ms: 0.25724124464011067\n",
      "  mean_inference_ms: 2.0376635928170543\n",
      "  mean_raw_obs_processing_ms: 0.23117165389670497\n",
      "time_since_restore: 6493.496466159821\n",
      "time_this_iter_s: 29.14122486114502\n",
      "time_total_s: 6493.496466159821\n",
      "timers:\n",
      "  learn_throughput: 74251.896\n",
      "  learn_time_ms: 3.448\n",
      "timestamp: 1604606688\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 227500\n",
      "training_iteration: 227\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_227/checkpoint-227\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-05-17\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9261.239081770182\n",
      "episode_reward_mean: 7539.126292303749\n",
      "episode_reward_min: 3890.1749329715967\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9140\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 228498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 3851.973876953125\n",
      "      mean_q: 2711.560302734375\n",
      "      min_q: 659.5020751953125\n",
      "      model: {}\n",
      "  num_steps_sampled: 228500\n",
      "  num_steps_trained: 58112256\n",
      "  num_target_updates: 37834\n",
      "iterations_since_restore: 228\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.48292682926829\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395030758711548\n",
      "  mean_env_wait_ms: 0.2572471970754453\n",
      "  mean_inference_ms: 2.037719775683142\n",
      "  mean_raw_obs_processing_ms: 0.2311847869305656\n",
      "time_since_restore: 6522.716691970825\n",
      "time_this_iter_s: 29.22022581100464\n",
      "time_total_s: 6522.716691970825\n",
      "timers:\n",
      "  learn_throughput: 72134.376\n",
      "  learn_time_ms: 3.549\n",
      "timestamp: 1604606717\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 228500\n",
      "training_iteration: 228\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_228/checkpoint-228\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-05-46\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9261.239081770182\n",
      "episode_reward_mean: 7704.045168931256\n",
      "episode_reward_min: 5027.257640399039\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9180\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 229500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4260.71435546875\n",
      "      mean_q: 2812.632080078125\n",
      "      min_q: 134.84719848632812\n",
      "      model: {}\n",
      "  num_steps_sampled: 229500\n",
      "  num_steps_trained: 58368256\n",
      "  num_target_updates: 38001\n",
      "iterations_since_restore: 229\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.556097560975616\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939506892822498\n",
      "  mean_env_wait_ms: 0.2572501515737188\n",
      "  mean_inference_ms: 2.0377355352464104\n",
      "  mean_raw_obs_processing_ms: 0.23119637731824827\n",
      "time_since_restore: 6551.304282903671\n",
      "time_this_iter_s: 28.58759093284607\n",
      "time_total_s: 6551.304282903671\n",
      "timers:\n",
      "  learn_throughput: 76071.515\n",
      "  learn_time_ms: 3.365\n",
      "timestamp: 1604606746\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 229500\n",
      "training_iteration: 229\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_229/checkpoint-229\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-06-14\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9261.239081770182\n",
      "episode_reward_mean: 7722.774566935023\n",
      "episode_reward_min: 5027.257640399039\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9220\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 230496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4260.09814453125\n",
      "      mean_q: 2941.88330078125\n",
      "      min_q: 846.3546752929688\n",
      "      model: {}\n",
      "  num_steps_sampled: 230500\n",
      "  num_steps_trained: 58624256\n",
      "  num_target_updates: 38167\n",
      "iterations_since_restore: 230\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.44749999999999\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394803851565549\n",
      "  mean_env_wait_ms: 0.25723587431844247\n",
      "  mean_inference_ms: 2.0376867221711206\n",
      "  mean_raw_obs_processing_ms: 0.231189599945525\n",
      "time_since_restore: 6579.522520780563\n",
      "time_this_iter_s: 28.21823787689209\n",
      "time_total_s: 6579.522520780563\n",
      "timers:\n",
      "  learn_throughput: 77126.098\n",
      "  learn_time_ms: 3.319\n",
      "timestamp: 1604606774\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 230500\n",
      "training_iteration: 230\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_230/checkpoint-230\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-06-43\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9315.909285575151\n",
      "episode_reward_mean: 7865.476985269699\n",
      "episode_reward_min: 5946.387228302658\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9260\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 231498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4429.3466796875\n",
      "      mean_q: 2919.134765625\n",
      "      min_q: 305.0725402832031\n",
      "      model: {}\n",
      "  num_steps_sampled: 231500\n",
      "  num_steps_trained: 58880256\n",
      "  num_target_updates: 38334\n",
      "iterations_since_restore: 231\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.34634146341463\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394211613153153\n",
      "  mean_env_wait_ms: 0.25721152572685013\n",
      "  mean_inference_ms: 2.037533835641188\n",
      "  mean_raw_obs_processing_ms: 0.23117657458589913\n",
      "time_since_restore: 6608.490703344345\n",
      "time_this_iter_s: 28.96818256378174\n",
      "time_total_s: 6608.490703344345\n",
      "timers:\n",
      "  learn_throughput: 76847.894\n",
      "  learn_time_ms: 3.331\n",
      "timestamp: 1604606803\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 231500\n",
      "training_iteration: 231\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_231/checkpoint-231\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-07-12\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9315.909285575151\n",
      "episode_reward_mean: 7878.152767368891\n",
      "episode_reward_min: 6026.966797307134\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9300\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 232500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4528.93994140625\n",
      "      mean_q: 2878.92333984375\n",
      "      min_q: 553.09521484375\n",
      "      model: {}\n",
      "  num_steps_sampled: 232500\n",
      "  num_steps_trained: 59136256\n",
      "  num_target_updates: 38501\n",
      "iterations_since_restore: 232\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.53902439024391\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393881669612504\n",
      "  mean_env_wait_ms: 0.25719211702824174\n",
      "  mean_inference_ms: 2.037412178713662\n",
      "  mean_raw_obs_processing_ms: 0.23117049467120862\n",
      "time_since_restore: 6637.26619887352\n",
      "time_this_iter_s: 28.775495529174805\n",
      "time_total_s: 6637.26619887352\n",
      "timers:\n",
      "  learn_throughput: 77206.51\n",
      "  learn_time_ms: 3.316\n",
      "timestamp: 1604606832\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 232500\n",
      "training_iteration: 232\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_232/checkpoint-232\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-07-40\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9315.909285575151\n",
      "episode_reward_mean: 7818.714956722264\n",
      "episode_reward_min: 5301.243574038148\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9340\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 233496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4585.794921875\n",
      "      mean_q: 3087.1708984375\n",
      "      min_q: 648.8328857421875\n",
      "      model: {}\n",
      "  num_steps_sampled: 233500\n",
      "  num_steps_trained: 59392256\n",
      "  num_target_updates: 38667\n",
      "iterations_since_restore: 233\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.46\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393661342556085\n",
      "  mean_env_wait_ms: 0.25716997862724794\n",
      "  mean_inference_ms: 2.037330757660776\n",
      "  mean_raw_obs_processing_ms: 0.23116145420553477\n",
      "time_since_restore: 6665.313146114349\n",
      "time_this_iter_s: 28.046947240829468\n",
      "time_total_s: 6665.313146114349\n",
      "timers:\n",
      "  learn_throughput: 72288.809\n",
      "  learn_time_ms: 3.541\n",
      "timestamp: 1604606860\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 233500\n",
      "training_iteration: 233\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_233/checkpoint-233\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-08-08\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9711.780685916543\n",
      "episode_reward_mean: 7659.452974828326\n",
      "episode_reward_min: 4896.813763022423\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9380\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 234498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4973.65771484375\n",
      "      mean_q: 2968.422119140625\n",
      "      min_q: 844.8457641601562\n",
      "      model: {}\n",
      "  num_steps_sampled: 234500\n",
      "  num_steps_trained: 59648256\n",
      "  num_target_updates: 38834\n",
      "iterations_since_restore: 234\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.34499999999999\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939358851112399\n",
      "  mean_env_wait_ms: 0.2571480046030744\n",
      "  mean_inference_ms: 2.0373509701264005\n",
      "  mean_raw_obs_processing_ms: 0.23115786342978278\n",
      "time_since_restore: 6693.84685587883\n",
      "time_this_iter_s: 28.53370976448059\n",
      "time_total_s: 6693.84685587883\n",
      "timers:\n",
      "  learn_throughput: 76023.041\n",
      "  learn_time_ms: 3.367\n",
      "timestamp: 1604606888\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 234500\n",
      "training_iteration: 234\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_234/checkpoint-234\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-08-37\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9711.780685916543\n",
      "episode_reward_mean: 7705.159734208379\n",
      "episode_reward_min: 4896.813763022423\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9420\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 235500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4894.58935546875\n",
      "      mean_q: 2921.3515625\n",
      "      min_q: 542.9212036132812\n",
      "      model: {}\n",
      "  num_steps_sampled: 235500\n",
      "  num_steps_trained: 59904256\n",
      "  num_target_updates: 39001\n",
      "iterations_since_restore: 235\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.400000000000006\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939345926094062\n",
      "  mean_env_wait_ms: 0.2571349090387364\n",
      "  mean_inference_ms: 2.0373624548391085\n",
      "  mean_raw_obs_processing_ms: 0.23116144370784547\n",
      "time_since_restore: 6722.860583305359\n",
      "time_this_iter_s: 29.01372742652893\n",
      "time_total_s: 6722.860583305359\n",
      "timers:\n",
      "  learn_throughput: 76656.421\n",
      "  learn_time_ms: 3.34\n",
      "timestamp: 1604606917\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 235500\n",
      "training_iteration: 235\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_235/checkpoint-235\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-09-06\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9711.780685916543\n",
      "episode_reward_mean: 7847.411161129263\n",
      "episode_reward_min: 4896.813763022423\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9460\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 236496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4897.74609375\n",
      "      mean_q: 3073.571533203125\n",
      "      min_q: 726.941162109375\n",
      "      model: {}\n",
      "  num_steps_sampled: 236500\n",
      "  num_steps_trained: 60160256\n",
      "  num_target_updates: 39167\n",
      "iterations_since_restore: 236\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.45609756097561\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939334326095286\n",
      "  mean_env_wait_ms: 0.2571240798208841\n",
      "  mean_inference_ms: 2.0373010703425773\n",
      "  mean_raw_obs_processing_ms: 0.23116602984598864\n",
      "time_since_restore: 6751.381838321686\n",
      "time_this_iter_s: 28.521255016326904\n",
      "time_total_s: 6751.381838321686\n",
      "timers:\n",
      "  learn_throughput: 77949.156\n",
      "  learn_time_ms: 3.284\n",
      "timestamp: 1604606946\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 236500\n",
      "training_iteration: 236\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_236/checkpoint-236\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-09-34\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9856.458377107978\n",
      "episode_reward_mean: 8222.679917722215\n",
      "episode_reward_min: 6037.130347371101\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9500\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 237498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5091.642578125\n",
      "      mean_q: 3159.72705078125\n",
      "      min_q: 994.4051513671875\n",
      "      model: {}\n",
      "  num_steps_sampled: 237500\n",
      "  num_steps_trained: 60416256\n",
      "  num_target_updates: 39334\n",
      "iterations_since_restore: 237\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4625\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393091018891746\n",
      "  mean_env_wait_ms: 0.2571055345886192\n",
      "  mean_inference_ms: 2.037186439194255\n",
      "  mean_raw_obs_processing_ms: 0.23115843865069338\n",
      "time_since_restore: 6779.746658563614\n",
      "time_this_iter_s: 28.3648202419281\n",
      "time_total_s: 6779.746658563614\n",
      "timers:\n",
      "  learn_throughput: 75509.27\n",
      "  learn_time_ms: 3.39\n",
      "timestamp: 1604606974\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 237500\n",
      "training_iteration: 237\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_237/checkpoint-237\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-10-02\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9856.458377107978\n",
      "episode_reward_mean: 8329.12077874233\n",
      "episode_reward_min: 6854.262942567468\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9540\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 238500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4915.82421875\n",
      "      mean_q: 3138.276123046875\n",
      "      min_q: 878.6510620117188\n",
      "      model: {}\n",
      "  num_steps_sampled: 238500\n",
      "  num_steps_trained: 60672256\n",
      "  num_target_updates: 39501\n",
      "iterations_since_restore: 238\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.385000000000005\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392451701847826\n",
      "  mean_env_wait_ms: 0.2570819317440063\n",
      "  mean_inference_ms: 2.0371055354648395\n",
      "  mean_raw_obs_processing_ms: 0.23114168374085942\n",
      "time_since_restore: 6807.891551971436\n",
      "time_this_iter_s: 28.144893407821655\n",
      "time_total_s: 6807.891551971436\n",
      "timers:\n",
      "  learn_throughput: 72647.314\n",
      "  learn_time_ms: 3.524\n",
      "timestamp: 1604607002\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 238500\n",
      "training_iteration: 238\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_238/checkpoint-238\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-10-31\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10410.976461456157\n",
      "episode_reward_mean: 8341.001473323484\n",
      "episode_reward_min: 6785.514476969838\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9580\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 239496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 4793.91943359375\n",
      "      mean_q: 3139.01611328125\n",
      "      min_q: 784.6846923828125\n",
      "      model: {}\n",
      "  num_steps_sampled: 239500\n",
      "  num_steps_trained: 60928256\n",
      "  num_target_updates: 39667\n",
      "iterations_since_restore: 239\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.582926829268295\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391929859655672\n",
      "  mean_env_wait_ms: 0.25706990736141555\n",
      "  mean_inference_ms: 2.037079292222561\n",
      "  mean_raw_obs_processing_ms: 0.23113461137196029\n",
      "time_since_restore: 6836.82203578949\n",
      "time_this_iter_s: 28.9304838180542\n",
      "time_total_s: 6836.82203578949\n",
      "timers:\n",
      "  learn_throughput: 74304.822\n",
      "  learn_time_ms: 3.445\n",
      "timestamp: 1604607031\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 239500\n",
      "training_iteration: 239\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_239/checkpoint-239\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-11-00\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10410.976461456157\n",
      "episode_reward_mean: 8338.345317384577\n",
      "episode_reward_min: 6305.977361425757\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9620\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 240498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5061.755859375\n",
      "      mean_q: 3203.9306640625\n",
      "      min_q: 723.35546875\n",
      "      model: {}\n",
      "  num_steps_sampled: 240500\n",
      "  num_steps_trained: 61184256\n",
      "  num_target_updates: 39834\n",
      "iterations_since_restore: 240\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.49024390243903\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391938488084389\n",
      "  mean_env_wait_ms: 0.2570644814950852\n",
      "  mean_inference_ms: 2.0370681573714595\n",
      "  mean_raw_obs_processing_ms: 0.23113308192460066\n",
      "time_since_restore: 6865.293342828751\n",
      "time_this_iter_s: 28.471307039260864\n",
      "time_total_s: 6865.293342828751\n",
      "timers:\n",
      "  learn_throughput: 75516.705\n",
      "  learn_time_ms: 3.39\n",
      "timestamp: 1604607060\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 240500\n",
      "training_iteration: 240\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_240/checkpoint-240\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-11-28\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10073.57810510043\n",
      "episode_reward_mean: 8316.383052243495\n",
      "episode_reward_min: 6092.308021306992\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9660\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 241500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5063.50146484375\n",
      "      mean_q: 3168.921142578125\n",
      "      min_q: 800.8137817382812\n",
      "      model: {}\n",
      "  num_steps_sampled: 241500\n",
      "  num_steps_trained: 61440256\n",
      "  num_target_updates: 40001\n",
      "iterations_since_restore: 241\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939189422661767\n",
      "  mean_env_wait_ms: 0.25704991950288614\n",
      "  mean_inference_ms: 2.0370193360949305\n",
      "  mean_raw_obs_processing_ms: 0.23113286205394182\n",
      "time_since_restore: 6893.646005153656\n",
      "time_this_iter_s: 28.352662324905396\n",
      "time_total_s: 6893.646005153656\n",
      "timers:\n",
      "  learn_throughput: 78185.843\n",
      "  learn_time_ms: 3.274\n",
      "timestamp: 1604607088\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 241500\n",
      "training_iteration: 241\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_241/checkpoint-241\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-11-57\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10325.825502544641\n",
      "episode_reward_mean: 8425.922665333863\n",
      "episode_reward_min: 6092.308021306992\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9700\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 242496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5269.31982421875\n",
      "      mean_q: 3189.654541015625\n",
      "      min_q: 652.3512573242188\n",
      "      model: {}\n",
      "  num_steps_sampled: 242500\n",
      "  num_steps_trained: 61696256\n",
      "  num_target_updates: 40167\n",
      "iterations_since_restore: 242\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.52\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391587993397367\n",
      "  mean_env_wait_ms: 0.2570229971846292\n",
      "  mean_inference_ms: 2.03693930561466\n",
      "  mean_raw_obs_processing_ms: 0.23112390961451404\n",
      "time_since_restore: 6921.988423585892\n",
      "time_this_iter_s: 28.342418432235718\n",
      "time_total_s: 6921.988423585892\n",
      "timers:\n",
      "  learn_throughput: 77466.079\n",
      "  learn_time_ms: 3.305\n",
      "timestamp: 1604607117\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 242500\n",
      "training_iteration: 242\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_242/checkpoint-242\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-12-26\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10325.825502544641\n",
      "episode_reward_mean: 8417.95999717387\n",
      "episode_reward_min: 5902.635575830936\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9740\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 243498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5048.4775390625\n",
      "      mean_q: 3152.3447265625\n",
      "      min_q: 619.2304077148438\n",
      "      model: {}\n",
      "  num_steps_sampled: 243500\n",
      "  num_steps_trained: 61952256\n",
      "  num_target_updates: 40334\n",
      "iterations_since_restore: 243\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.38333333333333\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391396962057846\n",
      "  mean_env_wait_ms: 0.25700292551284454\n",
      "  mean_inference_ms: 2.036857926235311\n",
      "  mean_raw_obs_processing_ms: 0.23111927215720773\n",
      "time_since_restore: 6951.001492738724\n",
      "time_this_iter_s: 29.01306915283203\n",
      "time_total_s: 6951.001492738724\n",
      "timers:\n",
      "  learn_throughput: 74617.222\n",
      "  learn_time_ms: 3.431\n",
      "timestamp: 1604607146\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 243500\n",
      "training_iteration: 243\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_243/checkpoint-243\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-12-54\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10440.205987039953\n",
      "episode_reward_mean: 8366.143170764693\n",
      "episode_reward_min: 5309.533598974347\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9780\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 244500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5198.83154296875\n",
      "      mean_q: 3368.523193359375\n",
      "      min_q: 636.4872436523438\n",
      "      model: {}\n",
      "  num_steps_sampled: 244500\n",
      "  num_steps_trained: 62208256\n",
      "  num_target_updates: 40501\n",
      "iterations_since_restore: 244\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.40250000000001\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391405618848497\n",
      "  mean_env_wait_ms: 0.25698685953427236\n",
      "  mean_inference_ms: 2.0367579256792476\n",
      "  mean_raw_obs_processing_ms: 0.23111509561737514\n",
      "time_since_restore: 6979.381734609604\n",
      "time_this_iter_s: 28.380241870880127\n",
      "time_total_s: 6979.381734609604\n",
      "timers:\n",
      "  learn_throughput: 76487.689\n",
      "  learn_time_ms: 3.347\n",
      "timestamp: 1604607174\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 244500\n",
      "training_iteration: 244\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_244/checkpoint-244\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-13-23\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10440.205987039953\n",
      "episode_reward_mean: 8471.363091952499\n",
      "episode_reward_min: 5309.533598974347\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9820\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 245496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5242.5244140625\n",
      "      mean_q: 3205.1689453125\n",
      "      min_q: 733.3129272460938\n",
      "      model: {}\n",
      "  num_steps_sampled: 245500\n",
      "  num_steps_trained: 62464256\n",
      "  num_target_updates: 40667\n",
      "iterations_since_restore: 245\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.35121951219512\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391862747159735\n",
      "  mean_env_wait_ms: 0.25698022107700513\n",
      "  mean_inference_ms: 2.0367285469387757\n",
      "  mean_raw_obs_processing_ms: 0.23111447908366453\n",
      "time_since_restore: 7008.298209428787\n",
      "time_this_iter_s: 28.91647481918335\n",
      "time_total_s: 7008.298209428787\n",
      "timers:\n",
      "  learn_throughput: 79796.509\n",
      "  learn_time_ms: 3.208\n",
      "timestamp: 1604607203\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 245500\n",
      "training_iteration: 245\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_245/checkpoint-245\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-13-51\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10440.205987039953\n",
      "episode_reward_mean: 8454.155528514033\n",
      "episode_reward_min: 5309.533598974347\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9860\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 246498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5269.6611328125\n",
      "      mean_q: 3318.826904296875\n",
      "      min_q: 911.3390502929688\n",
      "      model: {}\n",
      "  num_steps_sampled: 246500\n",
      "  num_steps_trained: 62720256\n",
      "  num_target_updates: 40834\n",
      "iterations_since_restore: 246\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.425\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392017155281478\n",
      "  mean_env_wait_ms: 0.25696476413976155\n",
      "  mean_inference_ms: 2.0367142063714794\n",
      "  mean_raw_obs_processing_ms: 0.23110569824685392\n",
      "time_since_restore: 7036.282117128372\n",
      "time_this_iter_s: 27.98390769958496\n",
      "time_total_s: 7036.282117128372\n",
      "timers:\n",
      "  learn_throughput: 75450.374\n",
      "  learn_time_ms: 3.393\n",
      "timestamp: 1604607231\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 246500\n",
      "training_iteration: 246\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_246/checkpoint-246\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-14-20\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10079.307579427958\n",
      "episode_reward_mean: 8443.889658775319\n",
      "episode_reward_min: 5375.3433380536735\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9900\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 247500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5295.6435546875\n",
      "      mean_q: 3403.320556640625\n",
      "      min_q: 773.9351806640625\n",
      "      model: {}\n",
      "  num_steps_sampled: 247500\n",
      "  num_steps_trained: 62976256\n",
      "  num_target_updates: 41001\n",
      "iterations_since_restore: 247\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.34146341463415\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392014410697916\n",
      "  mean_env_wait_ms: 0.2569482575200717\n",
      "  mean_inference_ms: 2.036644707281121\n",
      "  mean_raw_obs_processing_ms: 0.23110020134175258\n",
      "time_since_restore: 7065.217459440231\n",
      "time_this_iter_s: 28.93534231185913\n",
      "time_total_s: 7065.217459440231\n",
      "timers:\n",
      "  learn_throughput: 78453.196\n",
      "  learn_time_ms: 3.263\n",
      "timestamp: 1604607260\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 247500\n",
      "training_iteration: 247\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_247/checkpoint-247\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-14-48\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10079.307579427958\n",
      "episode_reward_mean: 8355.37326349449\n",
      "episode_reward_min: 3744.1687514614314\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9940\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 248496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5243.6201171875\n",
      "      mean_q: 3368.17138671875\n",
      "      min_q: 639.5628662109375\n",
      "      model: {}\n",
      "  num_steps_sampled: 248500\n",
      "  num_steps_trained: 63232256\n",
      "  num_target_updates: 41167\n",
      "iterations_since_restore: 248\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4175\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391649849044345\n",
      "  mean_env_wait_ms: 0.2569229656828354\n",
      "  mean_inference_ms: 2.0365039228725696\n",
      "  mean_raw_obs_processing_ms: 0.23108718472798148\n",
      "time_since_restore: 7093.490961074829\n",
      "time_this_iter_s: 28.27350163459778\n",
      "time_total_s: 7093.490961074829\n",
      "timers:\n",
      "  learn_throughput: 76079.6\n",
      "  learn_time_ms: 3.365\n",
      "timestamp: 1604607288\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 248500\n",
      "training_iteration: 248\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_248/checkpoint-248\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-15-17\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10011.62841450423\n",
      "episode_reward_mean: 8461.655347418326\n",
      "episode_reward_min: 3744.1687514614314\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 9980\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 249498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5221.75537109375\n",
      "      mean_q: 3483.4130859375\n",
      "      min_q: 1094.1480712890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 249500\n",
      "  num_steps_trained: 63488256\n",
      "  num_target_updates: 41334\n",
      "iterations_since_restore: 249\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.34634146341463\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939158730314775\n",
      "  mean_env_wait_ms: 0.2569053354885922\n",
      "  mean_inference_ms: 2.0363830406048518\n",
      "  mean_raw_obs_processing_ms: 0.23107449698534172\n",
      "time_since_restore: 7122.038211107254\n",
      "time_this_iter_s: 28.547250032424927\n",
      "time_total_s: 7122.038211107254\n",
      "timers:\n",
      "  learn_throughput: 67695.701\n",
      "  learn_time_ms: 3.782\n",
      "timestamp: 1604607317\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 249500\n",
      "training_iteration: 249\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_249/checkpoint-249\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-15-45\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10207.378948421218\n",
      "episode_reward_mean: 8559.130491314816\n",
      "episode_reward_min: 5039.665587835014\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10020\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 250500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5467.12939453125\n",
      "      mean_q: 3466.97265625\n",
      "      min_q: 845.3302612304688\n",
      "      model: {}\n",
      "  num_steps_sampled: 250500\n",
      "  num_steps_trained: 63744256\n",
      "  num_target_updates: 41501\n",
      "iterations_since_restore: 250\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.392307692307696\n",
      "  ram_util_percent: 15.899999999999997\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391408887316995\n",
      "  mean_env_wait_ms: 0.2568831987390638\n",
      "  mean_inference_ms: 2.0363163207232473\n",
      "  mean_raw_obs_processing_ms: 0.2310582971413496\n",
      "time_since_restore: 7150.165847063065\n",
      "time_this_iter_s: 28.127635955810547\n",
      "time_total_s: 7150.165847063065\n",
      "timers:\n",
      "  learn_throughput: 68139.041\n",
      "  learn_time_ms: 3.757\n",
      "timestamp: 1604607345\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 250500\n",
      "training_iteration: 250\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_250/checkpoint-250\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-16-14\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10207.378948421218\n",
      "episode_reward_mean: 8566.18893520135\n",
      "episode_reward_min: 5677.5316796302795\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10060\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 251496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5386.4169921875\n",
      "      mean_q: 3566.015625\n",
      "      min_q: 620.932373046875\n",
      "      model: {}\n",
      "  num_steps_sampled: 251500\n",
      "  num_steps_trained: 64000256\n",
      "  num_target_updates: 41667\n",
      "iterations_since_restore: 251\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.36341463414633\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391299698769838\n",
      "  mean_env_wait_ms: 0.2568633508463521\n",
      "  mean_inference_ms: 2.036211900751872\n",
      "  mean_raw_obs_processing_ms: 0.23104611416247742\n",
      "time_since_restore: 7179.020955085754\n",
      "time_this_iter_s: 28.85510802268982\n",
      "time_total_s: 7179.020955085754\n",
      "timers:\n",
      "  learn_throughput: 72431.199\n",
      "  learn_time_ms: 3.534\n",
      "timestamp: 1604607374\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 251500\n",
      "training_iteration: 251\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_251/checkpoint-251\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-16-43\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9825.86257699132\n",
      "episode_reward_mean: 8522.357586755686\n",
      "episode_reward_min: 6061.081422221381\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10100\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 252498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5428.55078125\n",
      "      mean_q: 3532.271484375\n",
      "      min_q: 1094.6282958984375\n",
      "      model: {}\n",
      "  num_steps_sampled: 252500\n",
      "  num_steps_trained: 64256256\n",
      "  num_target_updates: 41834\n",
      "iterations_since_restore: 252\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.363414634146345\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939131639885262\n",
      "  mean_env_wait_ms: 0.2568491118158465\n",
      "  mean_inference_ms: 2.0361009442186138\n",
      "  mean_raw_obs_processing_ms: 0.23103785803184984\n",
      "time_since_restore: 7207.680555820465\n",
      "time_this_iter_s: 28.659600734710693\n",
      "time_total_s: 7207.680555820465\n",
      "timers:\n",
      "  learn_throughput: 74500.217\n",
      "  learn_time_ms: 3.436\n",
      "timestamp: 1604607403\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 252500\n",
      "training_iteration: 252\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_252/checkpoint-252\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-17-11\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10172.710102468729\n",
      "episode_reward_mean: 8210.604315441382\n",
      "episode_reward_min: -15463.592819608748\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10140\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 253500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5493.8779296875\n",
      "      mean_q: 3599.98291015625\n",
      "      min_q: 688.677734375\n",
      "      model: {}\n",
      "  num_steps_sampled: 253500\n",
      "  num_steps_trained: 64512256\n",
      "  num_target_updates: 42001\n",
      "iterations_since_restore: 253\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.52439024390244\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391656580642746\n",
      "  mean_env_wait_ms: 0.2568392354382319\n",
      "  mean_inference_ms: 2.03600226552474\n",
      "  mean_raw_obs_processing_ms: 0.23103780684556757\n",
      "time_since_restore: 7236.209391593933\n",
      "time_this_iter_s: 28.528835773468018\n",
      "time_total_s: 7236.209391593933\n",
      "timers:\n",
      "  learn_throughput: 75460.98\n",
      "  learn_time_ms: 3.392\n",
      "timestamp: 1604607431\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 253500\n",
      "training_iteration: 253\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_253/checkpoint-253\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-17-39\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10172.710102468729\n",
      "episode_reward_mean: -4728.215344405035\n",
      "episode_reward_min: -165171.34143913537\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10180\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 254496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5429.80126953125\n",
      "      mean_q: 2501.9462890625\n",
      "      min_q: -31308.140625\n",
      "      model: {}\n",
      "  num_steps_sampled: 254500\n",
      "  num_steps_trained: 64768256\n",
      "  num_target_updates: 42167\n",
      "iterations_since_restore: 254\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.47692307692307\n",
      "  ram_util_percent: 15.899999999999997\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391792090113515\n",
      "  mean_env_wait_ms: 0.2568209113506221\n",
      "  mean_inference_ms: 2.0359428102183403\n",
      "  mean_raw_obs_processing_ms: 0.2310338183333645\n",
      "time_since_restore: 7264.2828104496\n",
      "time_this_iter_s: 28.073418855667114\n",
      "time_total_s: 7264.2828104496\n",
      "timers:\n",
      "  learn_throughput: 75746.31\n",
      "  learn_time_ms: 3.38\n",
      "timestamp: 1604607459\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 254500\n",
      "training_iteration: 254\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_254/checkpoint-254\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-18-08\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9428.170896857977\n",
      "episode_reward_mean: -5686.072727306663\n",
      "episode_reward_min: -165171.34143913537\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10220\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 255498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5647.8359375\n",
      "      mean_q: 3298.830810546875\n",
      "      min_q: -35650.6640625\n",
      "      model: {}\n",
      "  num_steps_sampled: 255500\n",
      "  num_steps_trained: 65024256\n",
      "  num_target_updates: 42334\n",
      "iterations_since_restore: 255\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.33902439024391\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391985000540061\n",
      "  mean_env_wait_ms: 0.2568033659512387\n",
      "  mean_inference_ms: 2.0358624035233115\n",
      "  mean_raw_obs_processing_ms: 0.23102886890637017\n",
      "time_since_restore: 7293.204516172409\n",
      "time_this_iter_s: 28.921705722808838\n",
      "time_total_s: 7293.204516172409\n",
      "timers:\n",
      "  learn_throughput: 78421.682\n",
      "  learn_time_ms: 3.264\n",
      "timestamp: 1604607488\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 255500\n",
      "training_iteration: 255\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_255/checkpoint-255\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-18-37\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 8943.073434591293\n",
      "episode_reward_mean: 6445.075385893073\n",
      "episode_reward_min: 881.7433623969555\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10260\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 256500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5900.361328125\n",
      "      mean_q: 2606.9931640625\n",
      "      min_q: -34724.45703125\n",
      "      model: {}\n",
      "  num_steps_sampled: 256500\n",
      "  num_steps_trained: 65280256\n",
      "  num_target_updates: 42501\n",
      "iterations_since_restore: 256\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.43809523809523\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393033896340942\n",
      "  mean_env_wait_ms: 0.2568046494545048\n",
      "  mean_inference_ms: 2.0358890564977212\n",
      "  mean_raw_obs_processing_ms: 0.2310408513787982\n",
      "time_since_restore: 7322.319862127304\n",
      "time_this_iter_s: 29.11534595489502\n",
      "time_total_s: 7322.319862127304\n",
      "timers:\n",
      "  learn_throughput: 78787.657\n",
      "  learn_time_ms: 3.249\n",
      "timestamp: 1604607517\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 256500\n",
      "training_iteration: 256\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_256/checkpoint-256\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-19-06\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9613.58128714934\n",
      "episode_reward_mean: 7048.436284221609\n",
      "episode_reward_min: 1664.5779471695423\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10300\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 257496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5659.82958984375\n",
      "      mean_q: 2635.078857421875\n",
      "      min_q: -37637.90234375\n",
      "      model: {}\n",
      "  num_steps_sampled: 257500\n",
      "  num_steps_trained: 65536256\n",
      "  num_target_updates: 42667\n",
      "iterations_since_restore: 257\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4375\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394135181780382\n",
      "  mean_env_wait_ms: 0.2568140726986358\n",
      "  mean_inference_ms: 2.0359328162939048\n",
      "  mean_raw_obs_processing_ms: 0.23105868302975563\n",
      "time_since_restore: 7350.7905213832855\n",
      "time_this_iter_s: 28.470659255981445\n",
      "time_total_s: 7350.7905213832855\n",
      "timers:\n",
      "  learn_throughput: 62478.068\n",
      "  learn_time_ms: 4.097\n",
      "timestamp: 1604607546\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 257500\n",
      "training_iteration: 257\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_257/checkpoint-257\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-19-34\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9642.227876320481\n",
      "episode_reward_mean: 7797.165613914113\n",
      "episode_reward_min: 2475.4809558317065\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10340\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 258498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5829.46728515625\n",
      "      mean_q: 3356.34130859375\n",
      "      min_q: -41414.9765625\n",
      "      model: {}\n",
      "  num_steps_sampled: 258500\n",
      "  num_steps_trained: 65792256\n",
      "  num_target_updates: 42834\n",
      "iterations_since_restore: 258\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.5775\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394598732790936\n",
      "  mean_env_wait_ms: 0.2568184998637805\n",
      "  mean_inference_ms: 2.03596513228359\n",
      "  mean_raw_obs_processing_ms: 0.2310653362083135\n",
      "time_since_restore: 7379.124617576599\n",
      "time_this_iter_s: 28.3340961933136\n",
      "time_total_s: 7379.124617576599\n",
      "timers:\n",
      "  learn_throughput: 70316.16\n",
      "  learn_time_ms: 3.641\n",
      "timestamp: 1604607574\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 258500\n",
      "training_iteration: 258\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_258/checkpoint-258\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-20-03\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 9642.227876320481\n",
      "episode_reward_mean: 8318.536066333636\n",
      "episode_reward_min: 4440.16787442565\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10380\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 259500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6078.01220703125\n",
      "      mean_q: 3474.974609375\n",
      "      min_q: -21533.390625\n",
      "      model: {}\n",
      "  num_steps_sampled: 259500\n",
      "  num_steps_trained: 66048256\n",
      "  num_target_updates: 43001\n",
      "iterations_since_restore: 259\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.329268292682926\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394385728208128\n",
      "  mean_env_wait_ms: 0.2568032110473708\n",
      "  mean_inference_ms: 2.035896467622753\n",
      "  mean_raw_obs_processing_ms: 0.23105730091541538\n",
      "time_since_restore: 7407.698628425598\n",
      "time_this_iter_s: 28.574010848999023\n",
      "time_total_s: 7407.698628425598\n",
      "timers:\n",
      "  learn_throughput: 66928.575\n",
      "  learn_time_ms: 3.825\n",
      "timestamp: 1604607603\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 259500\n",
      "training_iteration: 259\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_259/checkpoint-259\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-20-31\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10239.390382945538\n",
      "episode_reward_mean: 8596.830892685663\n",
      "episode_reward_min: 4440.16787442565\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10420\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 260496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5850.9091796875\n",
      "      mean_q: 2877.5693359375\n",
      "      min_q: -43522.875\n",
      "      model: {}\n",
      "  num_steps_sampled: 260500\n",
      "  num_steps_trained: 66304256\n",
      "  num_target_updates: 43167\n",
      "iterations_since_restore: 260\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.43414634146341\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394243263520313\n",
      "  mean_env_wait_ms: 0.256787440986649\n",
      "  mean_inference_ms: 2.0358395075519535\n",
      "  mean_raw_obs_processing_ms: 0.23105522126077205\n",
      "time_since_restore: 7436.268443107605\n",
      "time_this_iter_s: 28.569814682006836\n",
      "time_total_s: 7436.268443107605\n",
      "timers:\n",
      "  learn_throughput: 76044.577\n",
      "  learn_time_ms: 3.366\n",
      "timestamp: 1604607631\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 260500\n",
      "training_iteration: 260\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_260/checkpoint-260\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-21-00\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10239.390382945538\n",
      "episode_reward_mean: 8779.446283282039\n",
      "episode_reward_min: 6976.65024022758\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10460\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 261498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5972.60986328125\n",
      "      mean_q: 3346.027587890625\n",
      "      min_q: -34644.87890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 261500\n",
      "  num_steps_trained: 66560256\n",
      "  num_target_updates: 43334\n",
      "iterations_since_restore: 261\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.385000000000005\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394167841018149\n",
      "  mean_env_wait_ms: 0.2567708290974784\n",
      "  mean_inference_ms: 2.0357987140551366\n",
      "  mean_raw_obs_processing_ms: 0.23105379141751048\n",
      "time_since_restore: 7464.554797887802\n",
      "time_this_iter_s: 28.286354780197144\n",
      "time_total_s: 7464.554797887802\n",
      "timers:\n",
      "  learn_throughput: 77837.837\n",
      "  learn_time_ms: 3.289\n",
      "timestamp: 1604607660\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 261500\n",
      "training_iteration: 261\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_261/checkpoint-261\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-21-28\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10712.223023671191\n",
      "episode_reward_mean: 8841.23811833396\n",
      "episode_reward_min: 6761.05985365808\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10500\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 262500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6382.5830078125\n",
      "      mean_q: 3136.161376953125\n",
      "      min_q: -51149.1015625\n",
      "      model: {}\n",
      "  num_steps_sampled: 262500\n",
      "  num_steps_trained: 66816256\n",
      "  num_target_updates: 43501\n",
      "iterations_since_restore: 262\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.457499999999996\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394129447023225\n",
      "  mean_env_wait_ms: 0.2567509789555073\n",
      "  mean_inference_ms: 2.03578208661365\n",
      "  mean_raw_obs_processing_ms: 0.23104583101812742\n",
      "time_since_restore: 7492.689743280411\n",
      "time_this_iter_s: 28.134945392608643\n",
      "time_total_s: 7492.689743280411\n",
      "timers:\n",
      "  learn_throughput: 73574.197\n",
      "  learn_time_ms: 3.479\n",
      "timestamp: 1604607688\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 262500\n",
      "training_iteration: 262\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_262/checkpoint-262\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-21-56\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10712.223023671191\n",
      "episode_reward_mean: 8722.779582394181\n",
      "episode_reward_min: 6546.767727032304\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10540\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 263496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5703.12158203125\n",
      "      mean_q: 2953.91845703125\n",
      "      min_q: -49806.734375\n",
      "      model: {}\n",
      "  num_steps_sampled: 263500\n",
      "  num_steps_trained: 67072256\n",
      "  num_target_updates: 43667\n",
      "iterations_since_restore: 263\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.43499999999999\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393987374057726\n",
      "  mean_env_wait_ms: 0.2567266711787917\n",
      "  mean_inference_ms: 2.0357032456813102\n",
      "  mean_raw_obs_processing_ms: 0.2310298288112474\n",
      "time_since_restore: 7521.263071537018\n",
      "time_this_iter_s: 28.573328256607056\n",
      "time_total_s: 7521.263071537018\n",
      "timers:\n",
      "  learn_throughput: 75450.905\n",
      "  learn_time_ms: 3.393\n",
      "timestamp: 1604607716\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 263500\n",
      "training_iteration: 263\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_263/checkpoint-263\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-22-25\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10712.223023671191\n",
      "episode_reward_mean: 8755.517676458878\n",
      "episode_reward_min: 6332.421903200448\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10580\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 264498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5739.5986328125\n",
      "      mean_q: 3708.381103515625\n",
      "      min_q: 737.33251953125\n",
      "      model: {}\n",
      "  num_steps_sampled: 264500\n",
      "  num_steps_trained: 67328256\n",
      "  num_target_updates: 43834\n",
      "iterations_since_restore: 264\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.380487804878044\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393907165873187\n",
      "  mean_env_wait_ms: 0.25670768456486837\n",
      "  mean_inference_ms: 2.035625464961946\n",
      "  mean_raw_obs_processing_ms: 0.23101747491031305\n",
      "time_since_restore: 7549.966609477997\n",
      "time_this_iter_s: 28.703537940979004\n",
      "time_total_s: 7549.966609477997\n",
      "timers:\n",
      "  learn_throughput: 75347.131\n",
      "  learn_time_ms: 3.398\n",
      "timestamp: 1604607745\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 264500\n",
      "training_iteration: 264\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_264/checkpoint-264\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-22-53\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10551.41174074635\n",
      "episode_reward_mean: 8787.038247057177\n",
      "episode_reward_min: 6332.421903200448\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10620\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 265500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5626.9609375\n",
      "      mean_q: 3707.59228515625\n",
      "      min_q: 871.2799072265625\n",
      "      model: {}\n",
      "  num_steps_sampled: 265500\n",
      "  num_steps_trained: 67584256\n",
      "  num_target_updates: 44001\n",
      "iterations_since_restore: 265\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.44500000000001\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939387736288129\n",
      "  mean_env_wait_ms: 0.25669157950041604\n",
      "  mean_inference_ms: 2.0355769240048986\n",
      "  mean_raw_obs_processing_ms: 0.2310096264508376\n",
      "time_since_restore: 7578.244869232178\n",
      "time_this_iter_s: 28.278259754180908\n",
      "time_total_s: 7578.244869232178\n",
      "timers:\n",
      "  learn_throughput: 77763.988\n",
      "  learn_time_ms: 3.292\n",
      "timestamp: 1604607773\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 265500\n",
      "training_iteration: 265\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_265/checkpoint-265\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-23-22\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10717.666569158435\n",
      "episode_reward_mean: 8967.48260008085\n",
      "episode_reward_min: 6995.031058341265\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10660\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 266496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5649.97802734375\n",
      "      mean_q: 3799.580810546875\n",
      "      min_q: 824.0985717773438\n",
      "      model: {}\n",
      "  num_steps_sampled: 266500\n",
      "  num_steps_trained: 67840256\n",
      "  num_target_updates: 44167\n",
      "iterations_since_restore: 266\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.49249999999999\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393949236307293\n",
      "  mean_env_wait_ms: 0.25667685718375877\n",
      "  mean_inference_ms: 2.0355912409280053\n",
      "  mean_raw_obs_processing_ms: 0.2310059460093406\n",
      "time_since_restore: 7606.5479855537415\n",
      "time_this_iter_s: 28.30311632156372\n",
      "time_total_s: 7606.5479855537415\n",
      "timers:\n",
      "  learn_throughput: 74717.434\n",
      "  learn_time_ms: 3.426\n",
      "timestamp: 1604607802\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 266500\n",
      "training_iteration: 266\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_266/checkpoint-266\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-23-51\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10717.666569158435\n",
      "episode_reward_mean: 8972.484227237841\n",
      "episode_reward_min: 5422.34345126152\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10700\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 267498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5967.74609375\n",
      "      mean_q: 3986.73486328125\n",
      "      min_q: 943.6539306640625\n",
      "      model: {}\n",
      "  num_steps_sampled: 267500\n",
      "  num_steps_trained: 68096256\n",
      "  num_target_updates: 44334\n",
      "iterations_since_restore: 267\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.32142857142856\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939468705131338\n",
      "  mean_env_wait_ms: 0.2566841239020172\n",
      "  mean_inference_ms: 2.0356669733210295\n",
      "  mean_raw_obs_processing_ms: 0.23101737611723774\n",
      "time_since_restore: 7635.866324424744\n",
      "time_this_iter_s: 29.318338871002197\n",
      "time_total_s: 7635.866324424744\n",
      "timers:\n",
      "  learn_throughput: 78470.397\n",
      "  learn_time_ms: 3.262\n",
      "timestamp: 1604607831\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 267500\n",
      "training_iteration: 267\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_267/checkpoint-267\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-24-20\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10717.666569158435\n",
      "episode_reward_mean: 8960.026833169992\n",
      "episode_reward_min: 5422.34345126152\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10740\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 268500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5744.01171875\n",
      "      mean_q: 3816.25390625\n",
      "      min_q: 1007.494873046875\n",
      "      model: {}\n",
      "  num_steps_sampled: 268500\n",
      "  num_steps_trained: 68352256\n",
      "  num_target_updates: 44501\n",
      "iterations_since_restore: 268\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.417073170731705\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395458273869639\n",
      "  mean_env_wait_ms: 0.25669442615527616\n",
      "  mean_inference_ms: 2.0357274609680847\n",
      "  mean_raw_obs_processing_ms: 0.2310317117701174\n",
      "time_since_restore: 7664.589130401611\n",
      "time_this_iter_s: 28.722805976867676\n",
      "time_total_s: 7664.589130401611\n",
      "timers:\n",
      "  learn_throughput: 76717.216\n",
      "  learn_time_ms: 3.337\n",
      "timestamp: 1604607860\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 268500\n",
      "training_iteration: 268\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_268/checkpoint-268\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-24-48\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10879.039455100894\n",
      "episode_reward_mean: 9037.7191675461\n",
      "episode_reward_min: 6277.33895258978\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10780\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 269496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5748.0732421875\n",
      "      mean_q: 3883.287109375\n",
      "      min_q: 778.442138671875\n",
      "      model: {}\n",
      "  num_steps_sampled: 269500\n",
      "  num_steps_trained: 68608256\n",
      "  num_target_updates: 44667\n",
      "iterations_since_restore: 269\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.3975\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395885576574373\n",
      "  mean_env_wait_ms: 0.2566939278250103\n",
      "  mean_inference_ms: 2.0356938121767554\n",
      "  mean_raw_obs_processing_ms: 0.23103702491930192\n",
      "time_since_restore: 7692.99223279953\n",
      "time_this_iter_s: 28.4031023979187\n",
      "time_total_s: 7692.99223279953\n",
      "timers:\n",
      "  learn_throughput: 78238.826\n",
      "  learn_time_ms: 3.272\n",
      "timestamp: 1604607888\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 269500\n",
      "training_iteration: 269\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_269/checkpoint-269\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-25-17\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11042.398666979745\n",
      "episode_reward_mean: 9140.966891456581\n",
      "episode_reward_min: 6277.33895258978\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10820\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 270498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5562.306640625\n",
      "      mean_q: 3761.498291015625\n",
      "      min_q: 812.1021728515625\n",
      "      model: {}\n",
      "  num_steps_sampled: 270500\n",
      "  num_steps_trained: 68864256\n",
      "  num_target_updates: 44834\n",
      "iterations_since_restore: 270\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.42926829268291\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396166244945302\n",
      "  mean_env_wait_ms: 0.25668319285727087\n",
      "  mean_inference_ms: 2.0356186889165486\n",
      "  mean_raw_obs_processing_ms: 0.2310372853407935\n",
      "time_since_restore: 7721.54327249527\n",
      "time_this_iter_s: 28.551039695739746\n",
      "time_total_s: 7721.54327249527\n",
      "timers:\n",
      "  learn_throughput: 65349.731\n",
      "  learn_time_ms: 3.917\n",
      "timestamp: 1604607917\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 270500\n",
      "training_iteration: 270\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_270/checkpoint-270\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-25-46\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11042.398666979745\n",
      "episode_reward_mean: 9340.555492637903\n",
      "episode_reward_min: 6719.916769862175\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10860\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 271500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5769.6083984375\n",
      "      mean_q: 3863.714111328125\n",
      "      min_q: 699.4423217773438\n",
      "      model: {}\n",
      "  num_steps_sampled: 271500\n",
      "  num_steps_trained: 69120256\n",
      "  num_target_updates: 45001\n",
      "iterations_since_restore: 271\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.426829268292686\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396582774501933\n",
      "  mean_env_wait_ms: 0.25667746028981836\n",
      "  mean_inference_ms: 2.0355369186992958\n",
      "  mean_raw_obs_processing_ms: 0.23104067197724298\n",
      "time_since_restore: 7750.488909482956\n",
      "time_this_iter_s: 28.945636987686157\n",
      "time_total_s: 7750.488909482956\n",
      "timers:\n",
      "  learn_throughput: 78261.636\n",
      "  learn_time_ms: 3.271\n",
      "timestamp: 1604607946\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 271500\n",
      "training_iteration: 271\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_271/checkpoint-271\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-26-15\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11042.398666979745\n",
      "episode_reward_mean: 9307.972447345266\n",
      "episode_reward_min: 6719.916769862175\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10900\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 272496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5709.330078125\n",
      "      mean_q: 3873.9365234375\n",
      "      min_q: 907.4905395507812\n",
      "      model: {}\n",
      "  num_steps_sampled: 272500\n",
      "  num_steps_trained: 69376256\n",
      "  num_target_updates: 45167\n",
      "iterations_since_restore: 272\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.382926829268285\n",
      "  ram_util_percent: 15.90731707317073\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396867534799423\n",
      "  mean_env_wait_ms: 0.2566737780368499\n",
      "  mean_inference_ms: 2.0354651886205466\n",
      "  mean_raw_obs_processing_ms: 0.23104213225069173\n",
      "time_since_restore: 7779.411688327789\n",
      "time_this_iter_s: 28.922778844833374\n",
      "time_total_s: 7779.411688327789\n",
      "timers:\n",
      "  learn_throughput: 73234.47\n",
      "  learn_time_ms: 3.496\n",
      "timestamp: 1604607975\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 272500\n",
      "training_iteration: 272\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_272/checkpoint-272\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-26-43\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10833.70519271493\n",
      "episode_reward_mean: 9280.54039943396\n",
      "episode_reward_min: 6970.505502015352\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10940\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 273498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5657.95654296875\n",
      "      mean_q: 3828.851806640625\n",
      "      min_q: 949.4146728515625\n",
      "      model: {}\n",
      "  num_steps_sampled: 273500\n",
      "  num_steps_trained: 69632256\n",
      "  num_target_updates: 45334\n",
      "iterations_since_restore: 273\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.395\n",
      "  ram_util_percent: 15.930000000000001\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396843935627423\n",
      "  mean_env_wait_ms: 0.25666879238616025\n",
      "  mean_inference_ms: 2.0353505823344746\n",
      "  mean_raw_obs_processing_ms: 0.23104474304972847\n",
      "time_since_restore: 7807.982065916061\n",
      "time_this_iter_s: 28.570377588272095\n",
      "time_total_s: 7807.982065916061\n",
      "timers:\n",
      "  learn_throughput: 75747.914\n",
      "  learn_time_ms: 3.38\n",
      "timestamp: 1604608003\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 273500\n",
      "training_iteration: 273\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_273/checkpoint-273\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-27-12\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10892.588880002499\n",
      "episode_reward_mean: 9031.93986931347\n",
      "episode_reward_min: -689.1754653155804\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 10980\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 274500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5690.6953125\n",
      "      mean_q: 4030.34765625\n",
      "      min_q: 1091.48388671875\n",
      "      model: {}\n",
      "  num_steps_sampled: 274500\n",
      "  num_steps_trained: 69888256\n",
      "  num_target_updates: 45501\n",
      "iterations_since_restore: 274\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.43414634146341\n",
      "  ram_util_percent: 15.902439024390244\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939665659042845\n",
      "  mean_env_wait_ms: 0.25665666295129635\n",
      "  mean_inference_ms: 2.0352326875631555\n",
      "  mean_raw_obs_processing_ms: 0.23104216271761538\n",
      "time_since_restore: 7836.214193344116\n",
      "time_this_iter_s: 28.23212742805481\n",
      "time_total_s: 7836.214193344116\n",
      "timers:\n",
      "  learn_throughput: 67378.8\n",
      "  learn_time_ms: 3.799\n",
      "timestamp: 1604608032\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 274500\n",
      "training_iteration: 274\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_274/checkpoint-274\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-27-41\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10892.588880002499\n",
      "episode_reward_mean: 8978.50378996068\n",
      "episode_reward_min: -689.1754653155804\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11020\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 275496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5968.93994140625\n",
      "      mean_q: 3903.8173828125\n",
      "      min_q: 943.96435546875\n",
      "      model: {}\n",
      "  num_steps_sampled: 275500\n",
      "  num_steps_trained: 70144256\n",
      "  num_target_updates: 45667\n",
      "iterations_since_restore: 275\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.341463414634134\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396508256752735\n",
      "  mean_env_wait_ms: 0.2566443350881665\n",
      "  mean_inference_ms: 2.0350920844332334\n",
      "  mean_raw_obs_processing_ms: 0.23103954389400577\n",
      "time_since_restore: 7865.279317140579\n",
      "time_this_iter_s: 29.065123796463013\n",
      "time_total_s: 7865.279317140579\n",
      "timers:\n",
      "  learn_throughput: 76905.136\n",
      "  learn_time_ms: 3.329\n",
      "timestamp: 1604608061\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 275500\n",
      "training_iteration: 275\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_275/checkpoint-275\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-28-09\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10719.731305599213\n",
      "episode_reward_mean: 9112.295448326748\n",
      "episode_reward_min: 5923.481047667563\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11060\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 276498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5780.025390625\n",
      "      mean_q: 3901.637451171875\n",
      "      min_q: 810.0453491210938\n",
      "      model: {}\n",
      "  num_steps_sampled: 276500\n",
      "  num_steps_trained: 70400256\n",
      "  num_target_updates: 45834\n",
      "iterations_since_restore: 276\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.355\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939641298394071\n",
      "  mean_env_wait_ms: 0.25663169752678155\n",
      "  mean_inference_ms: 2.0349587738483557\n",
      "  mean_raw_obs_processing_ms: 0.23103616255360465\n",
      "time_since_restore: 7893.787055969238\n",
      "time_this_iter_s: 28.507738828659058\n",
      "time_total_s: 7893.787055969238\n",
      "timers:\n",
      "  learn_throughput: 67374.995\n",
      "  learn_time_ms: 3.8\n",
      "timestamp: 1604608089\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 276500\n",
      "training_iteration: 276\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_276/checkpoint-276\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-28-38\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10689.3604574427\n",
      "episode_reward_mean: 9129.31847631183\n",
      "episode_reward_min: 5515.109592072666\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11100\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 277500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6237.04541015625\n",
      "      mean_q: 4033.54638671875\n",
      "      min_q: 979.6270141601562\n",
      "      model: {}\n",
      "  num_steps_sampled: 277500\n",
      "  num_steps_trained: 70656256\n",
      "  num_target_updates: 46001\n",
      "iterations_since_restore: 277\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.46829268292682\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.0939625354854431\n",
      "  mean_env_wait_ms: 0.25662409215154086\n",
      "  mean_inference_ms: 2.0348568601329036\n",
      "  mean_raw_obs_processing_ms: 0.23103639231652295\n",
      "time_since_restore: 7922.367388486862\n",
      "time_this_iter_s: 28.5803325176239\n",
      "time_total_s: 7922.367388486862\n",
      "timers:\n",
      "  learn_throughput: 68803.141\n",
      "  learn_time_ms: 3.721\n",
      "timestamp: 1604608118\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 277500\n",
      "training_iteration: 277\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_277/checkpoint-277\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-29-07\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10850.081849575043\n",
      "episode_reward_mean: 9183.955089174811\n",
      "episode_reward_min: 5347.160271063447\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11140\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 278496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5861.57421875\n",
      "      mean_q: 4131.7119140625\n",
      "      min_q: 763.2791137695312\n",
      "      model: {}\n",
      "  num_steps_sampled: 278500\n",
      "  num_steps_trained: 70912256\n",
      "  num_target_updates: 46167\n",
      "iterations_since_restore: 278\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.32682926829268\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396550440787704\n",
      "  mean_env_wait_ms: 0.25662755879904453\n",
      "  mean_inference_ms: 2.0348633573677937\n",
      "  mean_raw_obs_processing_ms: 0.23104181571430277\n",
      "time_since_restore: 7951.184605836868\n",
      "time_this_iter_s: 28.817217350006104\n",
      "time_total_s: 7951.184605836868\n",
      "timers:\n",
      "  learn_throughput: 71915.036\n",
      "  learn_time_ms: 3.56\n",
      "timestamp: 1604608147\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 278500\n",
      "training_iteration: 278\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_278/checkpoint-278\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-29-36\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10850.081849575043\n",
      "episode_reward_mean: 9253.327513151839\n",
      "episode_reward_min: 5347.160271063447\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11180\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 279498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5859.6435546875\n",
      "      mean_q: 3988.71875\n",
      "      min_q: 981.7564697265625\n",
      "      model: {}\n",
      "  num_steps_sampled: 279500\n",
      "  num_steps_trained: 71168256\n",
      "  num_target_updates: 46334\n",
      "iterations_since_restore: 279\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.302439024390246\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396822465164327\n",
      "  mean_env_wait_ms: 0.2566270647287893\n",
      "  mean_inference_ms: 2.034821509977581\n",
      "  mean_raw_obs_processing_ms: 0.231039276376501\n",
      "time_since_restore: 7980.125907659531\n",
      "time_this_iter_s: 28.941301822662354\n",
      "time_total_s: 7980.125907659531\n",
      "timers:\n",
      "  learn_throughput: 76864.397\n",
      "  learn_time_ms: 3.331\n",
      "timestamp: 1604608176\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 279500\n",
      "training_iteration: 279\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_279/checkpoint-279\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-30-04\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11097.714579567313\n",
      "episode_reward_mean: 9256.464713484902\n",
      "episode_reward_min: 5347.160271063447\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11220\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 280500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5721.908203125\n",
      "      mean_q: 4056.433837890625\n",
      "      min_q: 706.0064086914062\n",
      "      model: {}\n",
      "  num_steps_sampled: 280500\n",
      "  num_steps_trained: 71424256\n",
      "  num_target_updates: 46501\n",
      "iterations_since_restore: 280\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.36585365853659\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396820616541753\n",
      "  mean_env_wait_ms: 0.256615424586602\n",
      "  mean_inference_ms: 2.0346988049277015\n",
      "  mean_raw_obs_processing_ms: 0.23102780003006942\n",
      "time_since_restore: 8008.748814821243\n",
      "time_this_iter_s: 28.622907161712646\n",
      "time_total_s: 8008.748814821243\n",
      "timers:\n",
      "  learn_throughput: 77608.296\n",
      "  learn_time_ms: 3.299\n",
      "timestamp: 1604608204\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 280500\n",
      "training_iteration: 280\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_280/checkpoint-280\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-30-33\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11097.714579567313\n",
      "episode_reward_mean: 9241.752016840355\n",
      "episode_reward_min: 5747.151303626597\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11260\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 281496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5978.33740234375\n",
      "      mean_q: 3855.925537109375\n",
      "      min_q: 947.24462890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 281500\n",
      "  num_steps_trained: 71680256\n",
      "  num_target_updates: 46667\n",
      "iterations_since_restore: 281\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.4225\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396548737724392\n",
      "  mean_env_wait_ms: 0.25659861074660595\n",
      "  mean_inference_ms: 2.0345914641062333\n",
      "  mean_raw_obs_processing_ms: 0.2310152160332749\n",
      "time_since_restore: 8037.145459413528\n",
      "time_this_iter_s: 28.396644592285156\n",
      "time_total_s: 8037.145459413528\n",
      "timers:\n",
      "  learn_throughput: 71846.705\n",
      "  learn_time_ms: 3.563\n",
      "timestamp: 1604608233\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 281500\n",
      "training_iteration: 281\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_281/checkpoint-281\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-31-01\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10909.648448824883\n",
      "episode_reward_mean: 9209.639909971413\n",
      "episode_reward_min: 5747.151303626597\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11300\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 282498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6011.07763671875\n",
      "      mean_q: 3866.941162109375\n",
      "      min_q: 890.5227661132812\n",
      "      model: {}\n",
      "  num_steps_sampled: 282500\n",
      "  num_steps_trained: 71936256\n",
      "  num_target_updates: 46834\n",
      "iterations_since_restore: 282\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.44\n",
      "  ram_util_percent: 15.919999999999998\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09396117414814519\n",
      "  mean_env_wait_ms: 0.2565756359504111\n",
      "  mean_inference_ms: 2.0344879592441303\n",
      "  mean_raw_obs_processing_ms: 0.23099782594092255\n",
      "time_since_restore: 8065.063852071762\n",
      "time_this_iter_s: 27.918392658233643\n",
      "time_total_s: 8065.063852071762\n",
      "timers:\n",
      "  learn_throughput: 75283.737\n",
      "  learn_time_ms: 3.4\n",
      "timestamp: 1604608261\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 282500\n",
      "training_iteration: 282\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_282/checkpoint-282\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-31-29\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10972.265124291182\n",
      "episode_reward_mean: 9139.77396511651\n",
      "episode_reward_min: 5747.151303626597\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11340\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 283500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5958.69384765625\n",
      "      mean_q: 3924.79296875\n",
      "      min_q: 938.8634033203125\n",
      "      model: {}\n",
      "  num_steps_sampled: 283500\n",
      "  num_steps_trained: 72192256\n",
      "  num_target_updates: 47001\n",
      "iterations_since_restore: 283\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.2925\n",
      "  ram_util_percent: 15.977500000000001\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395517208250709\n",
      "  mean_env_wait_ms: 0.2565515238416681\n",
      "  mean_inference_ms: 2.0343481616585266\n",
      "  mean_raw_obs_processing_ms: 0.23098205607403713\n",
      "time_since_restore: 8093.638083219528\n",
      "time_this_iter_s: 28.574231147766113\n",
      "time_total_s: 8093.638083219528\n",
      "timers:\n",
      "  learn_throughput: 71491.279\n",
      "  learn_time_ms: 3.581\n",
      "timestamp: 1604608289\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 283500\n",
      "training_iteration: 283\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_283/checkpoint-283\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-31-58\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11286.181342482567\n",
      "episode_reward_mean: 9093.717843018281\n",
      "episode_reward_min: 2899.5552032776177\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11380\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 284496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6255.13134765625\n",
      "      mean_q: 3884.052734375\n",
      "      min_q: 904.7272338867188\n",
      "      model: {}\n",
      "  num_steps_sampled: 284500\n",
      "  num_steps_trained: 72448256\n",
      "  num_target_updates: 47167\n",
      "iterations_since_restore: 284\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.412195121951235\n",
      "  ram_util_percent: 15.99268292682927\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09395059739205185\n",
      "  mean_env_wait_ms: 0.2565384754175954\n",
      "  mean_inference_ms: 2.0341892305193245\n",
      "  mean_raw_obs_processing_ms: 0.23097672844420544\n",
      "time_since_restore: 8122.543248653412\n",
      "time_this_iter_s: 28.905165433883667\n",
      "time_total_s: 8122.543248653412\n",
      "timers:\n",
      "  learn_throughput: 75595.924\n",
      "  learn_time_ms: 3.386\n",
      "timestamp: 1604608318\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 284500\n",
      "training_iteration: 284\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_284/checkpoint-284\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-32-27\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11286.181342482567\n",
      "episode_reward_mean: 9129.94742555776\n",
      "episode_reward_min: 2899.5552032776177\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11420\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 285498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5900.361328125\n",
      "      mean_q: 4022.466796875\n",
      "      min_q: 710.3428344726562\n",
      "      model: {}\n",
      "  num_steps_sampled: 285500\n",
      "  num_steps_trained: 72704256\n",
      "  num_target_updates: 47334\n",
      "iterations_since_restore: 285\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.415\n",
      "  ram_util_percent: 15.9025\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394535374891294\n",
      "  mean_env_wait_ms: 0.2565220856305508\n",
      "  mean_inference_ms: 2.0340986581964136\n",
      "  mean_raw_obs_processing_ms: 0.23097211712321516\n",
      "time_since_restore: 8150.81850528717\n",
      "time_this_iter_s: 28.275256633758545\n",
      "time_total_s: 8150.81850528717\n",
      "timers:\n",
      "  learn_throughput: 78415.955\n",
      "  learn_time_ms: 3.265\n",
      "timestamp: 1604608347\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 285500\n",
      "training_iteration: 285\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_285/checkpoint-285\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-32-55\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11286.181342482567\n",
      "episode_reward_mean: 9092.119720409666\n",
      "episode_reward_min: 2899.5552032776177\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11460\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 286500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5945.1611328125\n",
      "      mean_q: 4064.163818359375\n",
      "      min_q: 989.1087646484375\n",
      "      model: {}\n",
      "  num_steps_sampled: 286500\n",
      "  num_steps_trained: 72960256\n",
      "  num_target_updates: 47501\n",
      "iterations_since_restore: 286\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.47560975609756\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394038459163204\n",
      "  mean_env_wait_ms: 0.2565062996023759\n",
      "  mean_inference_ms: 2.034080684624176\n",
      "  mean_raw_obs_processing_ms: 0.23096196891853998\n",
      "time_since_restore: 8179.020660638809\n",
      "time_this_iter_s: 28.202155351638794\n",
      "time_total_s: 8179.020660638809\n",
      "timers:\n",
      "  learn_throughput: 75980.542\n",
      "  learn_time_ms: 3.369\n",
      "timestamp: 1604608375\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 286500\n",
      "training_iteration: 286\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_286/checkpoint-286\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-33-24\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10896.224707454443\n",
      "episode_reward_mean: 9218.702713116394\n",
      "episode_reward_min: 4283.669112384319\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11500\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 287496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5978.23974609375\n",
      "      mean_q: 4120.8271484375\n",
      "      min_q: 1130.9560546875\n",
      "      model: {}\n",
      "  num_steps_sampled: 287500\n",
      "  num_steps_trained: 73216256\n",
      "  num_target_updates: 47667\n",
      "iterations_since_restore: 287\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.380487804878044\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393711121921182\n",
      "  mean_env_wait_ms: 0.2564969207016965\n",
      "  mean_inference_ms: 2.034079241966406\n",
      "  mean_raw_obs_processing_ms: 0.23095531643744002\n",
      "time_since_restore: 8208.01434135437\n",
      "time_this_iter_s: 28.993680715560913\n",
      "time_total_s: 8208.01434135437\n",
      "timers:\n",
      "  learn_throughput: 76039.192\n",
      "  learn_time_ms: 3.367\n",
      "timestamp: 1604608404\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 287500\n",
      "training_iteration: 287\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_287/checkpoint-287\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-33-52\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10896.224707454443\n",
      "episode_reward_mean: 9418.819790619631\n",
      "episode_reward_min: 6861.350329428911\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11540\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 288498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5994.55810546875\n",
      "      mean_q: 4078.494140625\n",
      "      min_q: 852.8480224609375\n",
      "      model: {}\n",
      "  num_steps_sampled: 288500\n",
      "  num_steps_trained: 73472256\n",
      "  num_target_updates: 47834\n",
      "iterations_since_restore: 288\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.379999999999995\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393787565130689\n",
      "  mean_env_wait_ms: 0.25649063432892427\n",
      "  mean_inference_ms: 2.0341027675304217\n",
      "  mean_raw_obs_processing_ms: 0.2309539673241121\n",
      "time_since_restore: 8236.578503131866\n",
      "time_this_iter_s: 28.564161777496338\n",
      "time_total_s: 8236.578503131866\n",
      "timers:\n",
      "  learn_throughput: 70672.061\n",
      "  learn_time_ms: 3.622\n",
      "timestamp: 1604608432\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 288500\n",
      "training_iteration: 288\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_288/checkpoint-288\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-34-21\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10908.638562351465\n",
      "episode_reward_mean: 9385.475740080006\n",
      "episode_reward_min: 6630.580704808235\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11580\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 289500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5938.08203125\n",
      "      mean_q: 4096.6201171875\n",
      "      min_q: 891.010986328125\n",
      "      model: {}\n",
      "  num_steps_sampled: 289500\n",
      "  num_steps_trained: 73728256\n",
      "  num_target_updates: 48001\n",
      "iterations_since_restore: 289\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.37317073170732\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394040330629747\n",
      "  mean_env_wait_ms: 0.25648521173509764\n",
      "  mean_inference_ms: 2.0341402826528885\n",
      "  mean_raw_obs_processing_ms: 0.2309515284949235\n",
      "time_since_restore: 8265.252968788147\n",
      "time_this_iter_s: 28.674465656280518\n",
      "time_total_s: 8265.252968788147\n",
      "timers:\n",
      "  learn_throughput: 78040.936\n",
      "  learn_time_ms: 3.28\n",
      "timestamp: 1604608461\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 289500\n",
      "training_iteration: 289\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_289/checkpoint-289\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-34-50\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10908.638562351465\n",
      "episode_reward_mean: 9257.521948493342\n",
      "episode_reward_min: 5521.389056742191\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11620\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 290496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5984.9794921875\n",
      "      mean_q: 4063.542236328125\n",
      "      min_q: 1001.3280639648438\n",
      "      model: {}\n",
      "  num_steps_sampled: 290500\n",
      "  num_steps_trained: 73984256\n",
      "  num_target_updates: 48167\n",
      "iterations_since_restore: 290\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.510000000000005\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394058851502753\n",
      "  mean_env_wait_ms: 0.25647935279345435\n",
      "  mean_inference_ms: 2.0342283309951896\n",
      "  mean_raw_obs_processing_ms: 0.23094578689907813\n",
      "time_since_restore: 8293.70076584816\n",
      "time_this_iter_s: 28.447797060012817\n",
      "time_total_s: 8293.70076584816\n",
      "timers:\n",
      "  learn_throughput: 69057.139\n",
      "  learn_time_ms: 3.707\n",
      "timestamp: 1604608490\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 290500\n",
      "training_iteration: 290\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_290/checkpoint-290\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-35-18\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10908.638562351465\n",
      "episode_reward_mean: 9101.307491537043\n",
      "episode_reward_min: 5521.389056742191\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11660\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 291498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5952.21875\n",
      "      mean_q: 3883.010986328125\n",
      "      min_q: 726.2672119140625\n",
      "      model: {}\n",
      "  num_steps_sampled: 291500\n",
      "  num_steps_trained: 74240256\n",
      "  num_target_updates: 48334\n",
      "iterations_since_restore: 291\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.47073170731708\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394164974205826\n",
      "  mean_env_wait_ms: 0.2564713688992107\n",
      "  mean_inference_ms: 2.034236099642865\n",
      "  mean_raw_obs_processing_ms: 0.23093751849090055\n",
      "time_since_restore: 8322.051355361938\n",
      "time_this_iter_s: 28.350589513778687\n",
      "time_total_s: 8322.051355361938\n",
      "timers:\n",
      "  learn_throughput: 77637.476\n",
      "  learn_time_ms: 3.297\n",
      "timestamp: 1604608518\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 291500\n",
      "training_iteration: 291\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_291/checkpoint-291\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-35-46\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11196.260814450681\n",
      "episode_reward_mean: 9125.477000547704\n",
      "episode_reward_min: 5521.389056742191\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11700\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 292500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 5978.9921875\n",
      "      mean_q: 4111.6513671875\n",
      "      min_q: 1113.1055908203125\n",
      "      model: {}\n",
      "  num_steps_sampled: 292500\n",
      "  num_steps_trained: 74496256\n",
      "  num_target_updates: 48501\n",
      "iterations_since_restore: 292\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.394999999999996\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394217822531481\n",
      "  mean_env_wait_ms: 0.2564581256454545\n",
      "  mean_inference_ms: 2.0341713345940655\n",
      "  mean_raw_obs_processing_ms: 0.23092598039400222\n",
      "time_since_restore: 8350.494471788406\n",
      "time_this_iter_s: 28.443116426467896\n",
      "time_total_s: 8350.494471788406\n",
      "timers:\n",
      "  learn_throughput: 76753.41\n",
      "  learn_time_ms: 3.335\n",
      "timestamp: 1604608546\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 292500\n",
      "training_iteration: 292\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_292/checkpoint-292\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-36-15\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11391.570151984692\n",
      "episode_reward_mean: 9094.696458894496\n",
      "episode_reward_min: 6374.199718140066\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11740\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 293496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6012.0703125\n",
      "      mean_q: 4037.48876953125\n",
      "      min_q: 928.9622802734375\n",
      "      model: {}\n",
      "  num_steps_sampled: 293500\n",
      "  num_steps_trained: 74752256\n",
      "  num_target_updates: 48667\n",
      "iterations_since_restore: 293\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.5125\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09394143492135737\n",
      "  mean_env_wait_ms: 0.2564410789022081\n",
      "  mean_inference_ms: 2.034068483149733\n",
      "  mean_raw_obs_processing_ms: 0.23091401045891588\n",
      "time_since_restore: 8378.814025878906\n",
      "time_this_iter_s: 28.319554090499878\n",
      "time_total_s: 8378.814025878906\n",
      "timers:\n",
      "  learn_throughput: 70887.149\n",
      "  learn_time_ms: 3.611\n",
      "timestamp: 1604608575\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 293500\n",
      "training_iteration: 293\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_293/checkpoint-293\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-36-43\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11391.570151984692\n",
      "episode_reward_mean: 9263.809816435936\n",
      "episode_reward_min: 6379.370941966772\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11780\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 294498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6003.76708984375\n",
      "      mean_q: 4171.130859375\n",
      "      min_q: 1199.605712890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 294500\n",
      "  num_steps_trained: 75008256\n",
      "  num_target_updates: 48834\n",
      "iterations_since_restore: 294\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.470000000000006\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393641134136238\n",
      "  mean_env_wait_ms: 0.2564197060508569\n",
      "  mean_inference_ms: 2.0339873352109255\n",
      "  mean_raw_obs_processing_ms: 0.23089757255923182\n",
      "time_since_restore: 8406.787159919739\n",
      "time_this_iter_s: 27.97313404083252\n",
      "time_total_s: 8406.787159919739\n",
      "timers:\n",
      "  learn_throughput: 71463.207\n",
      "  learn_time_ms: 3.582\n",
      "timestamp: 1604608603\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 294500\n",
      "training_iteration: 294\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_294/checkpoint-294\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-37-11\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 10988.088700205088\n",
      "episode_reward_mean: 9276.179121940037\n",
      "episode_reward_min: 6379.370941966772\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11820\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 295500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6003.208984375\n",
      "      mean_q: 4159.83154296875\n",
      "      min_q: 1165.1502685546875\n",
      "      model: {}\n",
      "  num_steps_sampled: 295500\n",
      "  num_steps_trained: 75264256\n",
      "  num_target_updates: 49001\n",
      "iterations_since_restore: 295\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.335\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09393214165325223\n",
      "  mean_env_wait_ms: 0.25639852116542633\n",
      "  mean_inference_ms: 2.0338691701269833\n",
      "  mean_raw_obs_processing_ms: 0.23087978911022994\n",
      "time_since_restore: 8435.29633975029\n",
      "time_this_iter_s: 28.509179830551147\n",
      "time_total_s: 8435.29633975029\n",
      "timers:\n",
      "  learn_throughput: 77126.098\n",
      "  learn_time_ms: 3.319\n",
      "timestamp: 1604608631\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 295500\n",
      "training_iteration: 295\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_295/checkpoint-295\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-37-39\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11237.632796987891\n",
      "episode_reward_mean: 9291.178648305133\n",
      "episode_reward_min: 6361.491760104895\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11860\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 296496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6109.32666015625\n",
      "      mean_q: 3863.25830078125\n",
      "      min_q: 1140.7694091796875\n",
      "      model: {}\n",
      "  num_steps_sampled: 296500\n",
      "  num_steps_trained: 75520256\n",
      "  num_target_updates: 49167\n",
      "iterations_since_restore: 296\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.35999999999999\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392821954104015\n",
      "  mean_env_wait_ms: 0.2563727006311436\n",
      "  mean_inference_ms: 2.0337544403271646\n",
      "  mean_raw_obs_processing_ms: 0.23085828173490078\n",
      "time_since_restore: 8463.219952344894\n",
      "time_this_iter_s: 27.923612594604492\n",
      "time_total_s: 8463.219952344894\n",
      "timers:\n",
      "  learn_throughput: 77213.728\n",
      "  learn_time_ms: 3.315\n",
      "timestamp: 1604608659\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 296500\n",
      "training_iteration: 296\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_296/checkpoint-296\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-38-07\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11237.632796987891\n",
      "episode_reward_mean: 9285.960615003833\n",
      "episode_reward_min: 6361.491760104895\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11900\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 297498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6133.93310546875\n",
      "      mean_q: 4044.494140625\n",
      "      min_q: 1144.8359375\n",
      "      model: {}\n",
      "  num_steps_sampled: 297500\n",
      "  num_steps_trained: 75776256\n",
      "  num_target_updates: 49334\n",
      "iterations_since_restore: 297\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.36750000000001\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09392299856297273\n",
      "  mean_env_wait_ms: 0.2563408088012649\n",
      "  mean_inference_ms: 2.0336607204729034\n",
      "  mean_raw_obs_processing_ms: 0.23083168124364442\n",
      "time_since_restore: 8491.335281133652\n",
      "time_this_iter_s: 28.115328788757324\n",
      "time_total_s: 8491.335281133652\n",
      "timers:\n",
      "  learn_throughput: 73339.514\n",
      "  learn_time_ms: 3.491\n",
      "timestamp: 1604608687\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 297500\n",
      "training_iteration: 297\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_297/checkpoint-297\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-38-36\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11237.632796987891\n",
      "episode_reward_mean: 9157.340170799158\n",
      "episode_reward_min: 6361.491760104895\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11940\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 298500\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6089.22607421875\n",
      "      mean_q: 4100.6962890625\n",
      "      min_q: 872.8587036132812\n",
      "      model: {}\n",
      "  num_steps_sampled: 298500\n",
      "  num_steps_trained: 76032256\n",
      "  num_target_updates: 49501\n",
      "iterations_since_restore: 298\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.545\n",
      "  ram_util_percent: 15.9\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391836698252509\n",
      "  mean_env_wait_ms: 0.2563165190059365\n",
      "  mean_inference_ms: 2.033626908860675\n",
      "  mean_raw_obs_processing_ms: 0.23081416720218223\n",
      "time_since_restore: 8519.690233707428\n",
      "time_this_iter_s: 28.354952573776245\n",
      "time_total_s: 8519.690233707428\n",
      "timers:\n",
      "  learn_throughput: 68003.966\n",
      "  learn_time_ms: 3.764\n",
      "timestamp: 1604608716\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 298500\n",
      "training_iteration: 298\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_298/checkpoint-298\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-39-05\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11006.613866239786\n",
      "episode_reward_mean: 9213.602006769517\n",
      "episode_reward_min: 6784.453994750977\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 11980\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 299496\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6256.76611328125\n",
      "      mean_q: 4002.44384765625\n",
      "      min_q: 1083.0087890625\n",
      "      model: {}\n",
      "  num_steps_sampled: 299500\n",
      "  num_steps_trained: 76288256\n",
      "  num_target_updates: 49667\n",
      "iterations_since_restore: 299\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.33658536585365\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391690549454004\n",
      "  mean_env_wait_ms: 0.25630200683817056\n",
      "  mean_inference_ms: 2.033575269216348\n",
      "  mean_raw_obs_processing_ms: 0.2308059540540735\n",
      "time_since_restore: 8548.540682792664\n",
      "time_this_iter_s: 28.850449085235596\n",
      "time_total_s: 8548.540682792664\n",
      "timers:\n",
      "  learn_throughput: 69356.894\n",
      "  learn_time_ms: 3.691\n",
      "timestamp: 1604608745\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 299500\n",
      "training_iteration: 299\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_299/checkpoint-299\n",
      "custom_metrics: {}\n",
      "date: 2020-11-05_20-39-33\n",
      "done: false\n",
      "episode_len_mean: 25.0\n",
      "episode_reward_max: 11006.613866239786\n",
      "episode_reward_mean: 9317.423569969573\n",
      "episode_reward_min: 6784.453994750977\n",
      "episodes_this_iter: 40\n",
      "episodes_total: 12020\n",
      "experiment_id: 1863e8e860bc48cd871e9d86434ecc84\n",
      "hostname: fae47dddf38a\n",
      "info:\n",
      "  last_target_update_ts: 300498\n",
      "  learner:\n",
      "    default_policy:\n",
      "      max_q: 6077.1904296875\n",
      "      mean_q: 4168.4453125\n",
      "      min_q: 1053.55419921875\n",
      "      model: {}\n",
      "  num_steps_sampled: 300500\n",
      "  num_steps_trained: 76544256\n",
      "  num_target_updates: 49834\n",
      "iterations_since_restore: 300\n",
      "node_ip: 172.28.0.2\n",
      "num_healthy_workers: 0\n",
      "off_policy_estimator: {}\n",
      "perf:\n",
      "  cpu_util_percent: 56.33170731707318\n",
      "  ram_util_percent: 15.899999999999999\n",
      "pid: 370\n",
      "policy_reward_max: {}\n",
      "policy_reward_mean: {}\n",
      "policy_reward_min: {}\n",
      "sampler_perf:\n",
      "  mean_action_processing_ms: 0.09391693842234758\n",
      "  mean_env_wait_ms: 0.25629330851541643\n",
      "  mean_inference_ms: 2.0335048938764477\n",
      "  mean_raw_obs_processing_ms: 0.23080151711570976\n",
      "time_since_restore: 8577.142691612244\n",
      "time_this_iter_s: 28.602008819580078\n",
      "time_total_s: 8577.142691612244\n",
      "timers:\n",
      "  learn_throughput: 75415.399\n",
      "  learn_time_ms: 3.395\n",
      "timestamp: 1604608773\n",
      "timesteps_since_restore: 0\n",
      "timesteps_total: 300500\n",
      "training_iteration: 300\n",
      "\n",
      "Checkpoint saved at /root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/checkpoint_300/checkpoint-300\n"
     ]
    }
   ],
   "source": [
    "train_ddpg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "AInsheNP32Gu"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "oRLXVTNTLeY3"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/root/ray_results/DDPG_SimpleChain_2020-11-05_18-16-26wbllyek3/progress.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "mngQKOzELnNT",
    "outputId": "6b9d09b5-8760-4bfe-d873-11a82210546d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f8979d71128>]"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD5CAYAAAAqaDI/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deWBU5bn48e+ZJEN2woRM2AXCFtkUkS1GZBXjrVWvQaBg+V2oK7RWRDD1il6rWIG2WrEqKqWikpt041oaqApWJQRJLAU6iIEAYUtmspB1ksnM+f0xzCRDJixhJmeSPJ+/yJszk+flTM6Td1dUVVURQgjRaem0DkAIIYS2JBEIIUQnJ4lACCE6OUkEQgjRyUkiEEKITk4SgRBCdHLXlAiOHDnC9OnT2bx5MwBnz55lwYIFzJs3j5/85CfU19cDsHXrVv7zP/+T1NRUMjIyALDZbCxbtoy5c+cyf/58CgsLATh8+DBz5sxhzpw5rFq16lrCE0IIcQVanQhqamp44YUXmDhxorvstddeY968eXz44Ydcd911ZGZmUlNTw/r16/nd737H+++/z6ZNmygvL+fjjz8mOjqajz76iIcffph169YB8OKLL5KWlsaWLVuoqqri888/v/ZaCiGEaFGrE4Fer2fDhg0YjUZ3WU5ODtOmTQNgypQpZGdns3//fkaOHElUVBShoaGMGTOGvLw8srOzmTFjBgCTJk0iLy+P+vp6Tp8+zahRozzeQwghhP8Et/qFwcEEB3u+vLa2Fr1eD0BsbCxmsxmLxYLBYHBfYzAYmpXrdDoURcFisRAdHe2+1vUeQggh/KfVieByWtq54mrKW7o2Nze39YEJIUQndtNNNzUr82kiCA8Px2q1EhoaSlFREUajEaPRiMVicV9TXFzMDTfcgNFoxGw2M2zYMGw2G6qqEhcXR3l5ufta13tcaWWuhMlkIjExsVWvDTRSl8AkdQk8HaUecG11aemPaJ9OH500aRLbt28HYMeOHSQnJzN69GgOHDhARUUF1dXV5OXlMXbsWJKSksjKygJg586djB8/npCQEAYOHMi+ffs83kMIIYT/tLpFcPDgQX7xi19w+vRpgoOD2b59O2vXrmXlypWkp6fTq1cv7r77bkJCQli2bBmLFi1CURQee+wxoqKiSElJYffu3cydOxe9Xs/LL78MQFpaGs8++ywOh4PRo0czadIkn1VWCCFEc61OBCNGjOD9999vVr5x48ZmZbNmzWLWrFkeZUFBQaxevbrZtYMGDeLDDz9sbVhCCCGukqwsFkIIDazd/i2Lfvc12w+d0zoU/80aEkKIjujceSvz380hoksws4b3YO64vsSE6z2ucThUam12QkOCCNIpzd7j4OnzvL4zH4BPDxfzzgNjmX59PAB2h4rpbAXHLNWU19QzrEc04wYY+OTfRXx6uIg5Q4J8XidJBEIIcRXe/Pwo+cVVAOwvLOezw0VkPNw4lrnnWAlPZuznVFkt+mAdo/t0Zf6E67hrdC8UxZkUfrvrqMd7Ls/czydPTMYQoedHv9/HZ4eLPb5/29A4vvjOgt2hMrlnH0b7uE6SCIQQ4gqdO29ly9cnAXj+ruGs3fEtXx8v4/C5Cr4rqmLbgbP87WBjV099g4Ovj5fx9fEy/vzNafoawtl9tIT84ir0QTp2Lb+N5Zn7+Sq/hJt+/gn9Y8M5XlJDZJdgkgbFUl1n58t8C7u+dS6sfeS2BK6L8f3pwpIIhBDiCliq6li4cS9Wm4PpifH8cFJ/jhRV8kHOSb73my+x2Z0P6JAghUcmJ/DjaYOpsdnZ+s8zvLTNxM5vPXdJeGrWUHrFhPE/3x/BrF//A5td5XhJDQAr7hjGggnXoaoqz/7lEH87eJbHpgxi4aT+HD582Od1k0QghBAtKLBU81+/+5pz563U2uwAJMRFsOY+535o99/clw9yTrqTwPwJ/Xjo1gT6GsIBiA7SMX/CdUwZZuT3u49Tb3fgcKhEh4Ww6JYBF94vkt/MvZG8k+UoAArMubkvAIqi8MLdI3jh7hF+rackAiGEuMBcWcefvzlNyqie9I4J45WswxRYqt3fv7FfDG8tuIluEc7B4VF9Ylg/bwy/+uQI4wYYeOH7I9zjAE31jgnj6ZSWVwPPGtGTWSN6+r5CV0gSgRBCAP8+U8G8d/ZQXmPjw70nuem6bvzt4DmCdQpZj99KRJcgekSHNnvQ3zmqJ3eO0u4h7guSCIQQAnhx278pr7EBzi4hV0vgiZlDGGSM1DI0v5NEIITosIorrGTmneL02VL+q3sVCXHeH+h7C0r5Kr+EqNBgPvrRBH676yiDjJF8b3RPBhmj2jjqtieJQAjRrjkcKjqdwpGiSnYcOkfvbmEM79WVmPAQ7nszm5Olzpk4Ww78gw8Xj2f8wNhm7/G/+5xH5S6c1J8Rvbuy/gdj2rQOWpNEIIRoV6w2OxVWG5FdgnnhYxMZ+wpRFNwzdy7WPzYcQxeVvDO1bPm6sFkiqGuwu7d5+P4Nvf0efyCSRCCEaBfsDpWnMv/FH/JOtXjNmH4xxEeHuhd1DeweQcbDE8k9eJgH/3yKnd8W02B3EBzUuM3al99ZqLQ2MKxHVIcfC2iJJAIhRLvwStZhdxLoHqmnrMZGkKLw9gM3UV1n59tzFTw0OYGILsF8aipi24Fz/HTGYGIju9AnOoQB3SMosFTzTWE5N/dvPD537/FSAGZc2OunM5JEIIQIeA12B5v3nAAg/cEJjB8YS019A1abA8OFOf1Np3BOS4xnWmLjg11RFCYmxFJgqebAqfMeieDw2UoAhvfq2hZVCUiSCIQQAe/gmQqq6+0M6B7h7uMP1wdz0aaflxQW4ty103HRWeiHz1UAkNiz488OaomcRyCECDi2C1sxuOw5VgLAhIGGll5yWa7doJsmgtLqeooq6gjXB9G3W3ir37u9kxaBECJg2B0qP03/Jx//6wzdI7vw/F3DuWNkT7KPOhPB+AHNp35eKd2FFcFNGwSu1sDQHlHovJwb0Fn4NBFkZGSwdetW99cHDx5kxIgR1NTUEB7uzLYrVqxgxIgRvPPOO2RlZaEoCkuWLGHy5MlUVlaybNkyKisrCQ8PZ926dcTExPgyRCFEgKq02li7/Vu27j8DQHFlHY9+mMczd17PP74zE6RTmJTQ+kTg2hqiSUODb885xweG9ei83ULg40SQmppKamoqAHv37uVvf/sb+fn5rF69miFDhrivKywsZNu2bWzZsoWqqirmzZvHLbfcwqZNmxg3bhyLFy8mPT2dDRs2sHz5cl+GKIQIQJVWGymvfUFhaS0Ab86/ieyjFjZln+CFj/8NOPfiN0aHtvpneOsaOnFh2+eWVhx3Fn4bI1i/fj2PPvqo1+/l5OSQnJyMXq/HYDDQu3dv8vPzyc7OZsaMGQBMmTKF7Oxsf4UnhAgg63cepbC0lsguway+dySzRvTgyduH0uPCg396opGl0wZd089o7BpqTASnypyJp0+3sGt67/bOL2ME//rXv+jZsydxcXEAvPbaa5SVlZGQkEBaWhoWiwWDoXHQx2AwYDabPcpjY2MpLi72+v5CiI6jwmpj41cFAGxePJ4b+jq7g6NCQ9i6JInztTYGx197143ibhE0lp0qc7YI+nTigWLwUyLIzMzknnvuAeCBBx5g6NCh9OvXj1WrVvHBBx80u15Vmy8N91bWlMlkalVsVqu11a8NNFKXwCR1uTqfHaukrsHBiPhQulSdxWQ62+waU+m1/Qyr1UrJhW6g4mIzJlMDqqpyssR59nCNuRBTxZlr+yFtxB/3xC+JICcnh2eeeQbA3dUDMHXqVLZt28b48eMpKChwlxcVFWE0GjEajZjNZqKiotxlLUlMbPmQh0sxmUytfm2gkboEJqnL1fnV1/sASB2fQGJif7/8DJPJhDEuAijH0L07iYlDOF9jo8ZWQGSXYG4ePdzrgTKB6FruSW5urtdyn48RFBUVERERgV6vR1VVFi5cSEWFc4pWTk4OgwcPZsKECezatYv6+nqKioooLi5m0KBBJCUlkZWVBcCOHTtITk72dXhCiABiqarj8yPOs3xnjejh15/lGiNwzR8tdHcLhbWbJOAvPm8RmM1mdz+/oijMnj2bhQsXEhYWRnx8PEuXLiUsLIzZs2czf/58FEXhueeeQ6fTsWDBApYvX868efOIjo5mzZo1vg5PCKGxmvoG/ut3XxOuD0YB6hocTBtmJP4aZgRdCd1FYwQyUNzI54nAtUbAJSUlhZSUlGbXLViwgAULFniURURE8MYbb/g6JCFEAPntrqPsOebZ6f/49CEtXO07jesInJlABoobycpiIUSbsNkd/Pijb9xbREfog4jvGsoPxl/HyD7+3/BNd9GCMtdRlH0NkggkEQgh2kTOsVJ3Enhy5hCWTB3cpj+/cYjAmQmOmp0zhhLiIto0jkAkm84JIdrEp4eLAHho8sA2TwLQfGXxMbOzRdDZVxWDJAIhRBtQVZXPDjsXiM5I1OYAmKZdQxVWG8WVdXQJ1tE7RgaLJREIIfzudHktJ0pq6BoWwo39umkSg9Jk91FXa2BA94hOveuoiyQCIYTf5Rc7++Ov7xlNkEYP3qZdQ0cvxJPQSc8ovpgkAiGE3x2/MEOnf3ftBmabbjrnWkzWP1ZmDIEkAiFEG3BN1RyoYSJouulcg905YBwaHKRZPIFEEoEQwu8KLmz4pmWLoOmCMtfMIRkfcJJEIITwO1fX0IDu2nXFNN1iwrWorJNvMeQmiUAI4Vf1DQ5OldWgU7Rdxdt0jMC1qEwnmQCQRCCE8LOTpTU4VOjdLYwuGvbJ65psPuruGpI8AEgiEEL4WYG7W0jbqZqeYwTOMmkROEkiEEL4XIPdgePC09Y9PqDxVM2mK4tdLYLOfg6BiyQCIYRPnSypYcwLf2fFH/4FwDFL4ypeLbke+c4xAue/pWvISRKBEMKnNuecoMLaQGbeKU6W1ATEYjIA3YWnncf0UWkRAJIIhBA+VNdgJzP3FOAclP199nGOlwRGi8Bb15C0CJzkPAIhhM/844iF0up6ukfqsVTVsyn7ODa7SkiQovkun94Gi2WMwElaBEIIn/n7v50Hzyyc1J+bruuG7cJWDgO6RxAcpO3jxj19FGQdwUV82iLIycnhJz/5CYMHOw+dGDJkCIsXL+app57CbrcTFxfHmjVr0Ov1bN26lU2bNqHT6Zg9ezapqanYbDZWrlzJmTNnCAoKYvXq1fTt29eXIQoh/MTuUPnUdOHMget7cF1sBLknygBYfvswLUMDPBeUORyuMg0DCiA+7xoaN24cr732mvvrp59+mnnz5nHHHXfwy1/+kszMTO6++27Wr19PZmYmISEh3HfffcyYMYOdO3cSHR3NunXr+PLLL1m3bh2//vWvfR2iEMIPcgpKKKmup58hnCHxkQwyRlJgqWZE72imDtPmMJqm3FtMOJDB4ov4va2Wk5PDtGnTAJgyZQrZ2dns37+fkSNHEhUVRWhoKGPGjCEvL4/s7GxmzJgBwKRJk8jLy/N3eEKIK+RaF9CSD/acBODuG3qhKApBOoUfTxscEEnAydsYgYbhBBCftwjy8/N5+OGHOX/+PEuWLKG2tha9Xg9AbGwsZrMZi8WCwWBwv8ZgMDQr1+l0KIpCfX29+/VNmUymVsVntVpb/dpAI3UJTB2tLhm78nju0yLq7A5mDY5m8VgDhedtXBejJyTI+SQtrWkg6+BZdArcbKgPuPpbrVbOFDtnM1VUVmK3Ov8GPnfuLCZTlZahXTV/fL58mgj69+/PkiVLuOOOOygsLOSBBx7Abre7v+8aoLnY1ZYDJCYmtipGk8nU6tcGGqlLYGqPdSmwVPN+9gmWTB2EIaLxDy+TycSnB2uotjk71T/+toJvyxx8V1zF5CFxvLfwZoJ0Clv2nsSuwvREI8ljR2pVjRaZTCb69TUARURERBIVGgxU0ad3LxIT+2gd3lW5ls9Xbm6u13Kfdg3Fx8eTkpKCoij069eP7t27c/78eaxWKwBFRUUYjUaMRiMWi8X9uuLiYne52WwGwGazoaqq19aAEMJ3HA6V+9/K5r2vCnjxr55/aVbV292Hzr85fwyKAt9dOObx8yNm3vuyAIA9x0oASB4c14aRXx3PBWUXyqRvCPBxIti6dSvvvvsuAGazmZKSEu699162b98OwI4dO0hOTmb06NEcOHCAiooKqqurycvLY+zYsSQlJZGVlQXAzp07GT9+vC/DE0J48eHekxRX1gHwx29OUWG1ub/3SX4V9XYHkxJimTWiJ7OG9/B47d9NRaiqyp5jpQBMGBjbdoFfJffh9cheQxfzadfQ1KlTefLJJ/n000+x2Ww899xzJCYmsmLFCtLT0+nVqxd33303ISEhLFu2jEWLFqEoCo899hhRUVGkpKSwe/du5s6di16v5+WXX/ZleEKIi/zjiJlVWw+5v1ZV+GPuKRYmDeDs+Vp+/0/nA/6Hk/oDsPz2oRRVWEkd25en/3gA05kKCizVnKuwYojQMziAD4NvurJY9hry5NNEEBkZyZtvvtmsfOPGjc3KZs2axaxZszzKXGsHhBC+p6oqlXUN6IN02OwOIvTB/Pyv/8buUHl4cgKj+3TlkQ/y+H32CR6Y2J8Pc05Sa1OZcX08M693zvwZGBfJHx9NAmDdjiNYqupYtGkfALcM6h7QRz823XROpo96ki0mhOjg1m7/lk3Zx+nZNZQjRc7+/WCdwszh8RwpqqJn11CemDEEnQI9u4ZyzFLNl/kWvj7ubA2k3tTHaxfK8F7RfH7ETIGlmm7hITydov2isUvReTuzWPIAIFtMCNGhVdU18PYXx6i0NriTAECDQ2XbAed2ED9KHog+WEdwkI654/oBkJl7in8WlgNw03XdvL53003knv/+CHp21XYvocvxXFDm/LeMEThJIhCiA7E7VKy2xinb2w6cpb7BQVRoMG/8YAz//p/bKVidwsJJ/QkJUnhsSoK7/x/gzlE9Adi6/wxWm4M+0SHERnbx+rNuGdQdgD7dwvjehdcFsqabzsleQ56ka0iIDsLuUFm4cS/7C8v5v6W3cF1sBFv/eQaAZ+5MJGVk48P6ubuG87M7Ewm5aCO4hLhIBhsj3VNErzeGtvjzpiUaeXvBTYwfENsu/rL2PLPYs6yzkxaBEB3Exq8K+OI7CxXWBl7Z/i1Wm529F/r5Z1zfo9n1FycBl7tv7A2AIULP3YnRLf48RVGYObwHXcNDfBC9/7kGslVksPhi0iIQogNosDt4Y9dR99d//ddZJg6Mpb7BwbAeUR6rhS/n4ckJjBtgYESvrhw/esQf4WrCPUagInsNXURaBEJ0ALuPllBaXU9CXAT3XviL3rVKeFJC96t6ryCdws39DYTpg3wep7ZkjKAlkgiE6AD+/M1pAP5jVC8mD3Vu81B7YdB4YkLgrvZtS54tAkkETUnXkBDt3K/+foQ/fnMaRYHvje5FbJNuIGNUF24dcnUtgo5KDqZpmbQIhGjHzJV1rN+Zj06BX/znKAYZI+kWoWfCQOd27i/eM5IuwR2ti6d1vC0oaw+zndqCtAiEaMcyc0/R4FCZnhjP7LGNx7r+Zu4YTpfXckPfGA2jCyxKkwVlsteQJ0kEQrRTNruDD3JOAPCD8f08vhcX1YW4KO8LwTornZfdRwN5b6S2JF1DQgQ4VVX55mQZewtKPY6L/FPeaU6V1TKwewS3DgnccwAChes8AlX2GmpGWgRCBDC7Q+Wh93P5xFQEQPLg7mz6f+MAeGNXPgA/njaYIHmiXZbi9cxi+X8DSQRCBLQ/5p3iE1MRUaHBVFob+OI7C98VV1FSVcfxkhp6dQ3le6N7aR1mu9B0+qjqLpNEANI1JETAsjtUfvl358re//n+cO6+wfnA/+u/zrD6b4cBuG9sX2kNXCHvm85pGVHgkBaBEAGqwFLF2fNWekSH8v3RvalvcPDnf57htc+cXUIhQQqpN7Wvg9e15LnpnCwoa0oSgRAB6uDpCgBG9umKTqcwcWDjwrBRfbrys5RE+hrCtQqv3fFYR3BhQZnkASefJ4JXXnmF3NxcGhoaeOihh/jss884dOgQMTHO+cyLFi3itttuY+vWrWzatAmdTsfs2bNJTU3FZrOxcuVKzpw54z62sm/fvpf5iUJ0TIfOnAdgRK+uAPQ1hDEpIRZzZR0bF97c4jkBwrvGlcXSIriYTxPBnj17+O6770hPT6esrIx77rmHCRMm8MQTTzBlyhT3dTU1Naxfv57MzExCQkK47777mDFjBjt37iQ6Opp169bx5Zdfsm7dOn7961/7MkQh2g1Xi2B4L+dW0Iqi8OGPJuBwqDL/vRXcC8pU1b2gTPKAk08Hi2+++WZeffVVAKKjo6mtrcVutze7bv/+/YwcOZKoqChCQ0MZM2YMeXl5ZGdnM2PGDAAmTZpEXl6eL8MTot1QVbWxRdC7q8f3JAm0jiJjBC3yaYsgKCiI8HBnn2VmZia33norQUFBbN68mY0bNxIbG8t///d/Y7FYMBgM7tcZDAbMZrNHuU6nQ1EU6uvr0eub76VuMplaFaPVam31awON1CUw+aIuluoGKqwNRHfRUXr6GGVntHlgdZT7YrVaMR91ntdQV1+PTnX+DVxw7Bj20is/qyEQ+OOe+GWw+JNPPiEzM5P33nuPgwcPEhMTQ2JiIm+//Tavv/46N954o8f1rqlcF2upHCAxMbFVsZlMpla/NtBIXQKTL+qyO98CnGRwj65cf/31vgmsFTrKfTGZTPTsNQA4SVBwMCEhwYCNQYMSSIiL1Dq8q3It9yQ3N9druc/XEXzxxRe8+eabbNiwgaioKCZOnOgOeurUqRw5cgSj0YjFYnG/pri4GKPRiNFoxGw2A2Cz2VBV1WtrQIiO7pilGoCB3SM0jqTjkPMIWubTRFBZWckrr7zCW2+95Z4ltHTpUgoLCwHIyclh8ODBjB49mgMHDlBRUUF1dTV5eXmMHTuWpKQksrKyANi5cyfjx4/3ZXhCtBvHzM5EMCBOEoGvKE3PI5DdRz34tGto27ZtlJWV8fjjj7vL7r33Xh5//HHCwsIIDw9n9erVhIaGsmzZMhYtWoSiKDz22GNERUWRkpLC7t27mTt3Lnq9npdfftmX4QnRbhRYqgAY2L19dVsEMllQ1jKfJoL777+f+++/v1n5Pffc06xs1qxZzJo1y6PMtXZAiM6uwNU1JC0Cn/HcYsJVpmFAAUT2GhIiwNQ3OCgsq0VR4LpYWTnsKzJG0DJJBEIEmJOlNdgdKn26hckxkz6keDmqUhKBkyQCIQLMMbOMD/iD5xiBZ1lnJ4lAiADjGh8YIFNHfUrnZRtqOZjGSRKBEAHGlQgSZKDYpzx2H5UWgQdJBEIEGPcaAuka8inZa6hlkgiECDDHZOqoX3gkAockgqYkEQgRQM7X2rBU1REaoqNHdKjW4XQoOm/rCOQJCEgiECKgmM46zyAYGh8l2037mE6mj7ZIEoEQAeTgaecZBMMvOoNAXDvPBWWeZZ2dJAIhAogrEbiOpxS+03SqqF1aBB4kEQgRQA6ecXYNjegdrXEkHZOrBWB3uNYRaBhMAJFEIESAqK5r4Ki5imCdwtAeUVqH0yG5WgB2mTXkQRKBEAEi72QZqgrX94qWPYb85OLnviQCJ0kEQgSIPcdKAJgwMFbjSDqui7eUkMFiJ0kEQgSIPcdKAZgw0KBxJB3XxQ9+2WvISRKBEAGgpr6B/YXl6BS4ub8kAn9p2hUkrYFGkgiECADHzNU0OFQS4iKJCg3ROpwOyzMRSCZw8elRlb7y0ksvsX//fhRFIS0tjVGjRmkdkhB+VVhaA0A/g5xI5k9Nn/2SCBoFXCLYu3cvJ06cID09naNHj5KWlkZ6errWYQnhV6fKagHoK4nAr5o++iUPNAq4rqHs7GymT58OQEJCAufPn6eqqkrjqITwr8IyZ4ugT7cwjSPp2Jru3yQtgkYBlwgsFgvdunVzf20wGDCbzRpGJIT/ubqGpEXgXzJY7F3AdQ1dzHWk3MVMJlOr3s9qtbb6tYFG6hKYWlOX/HPlADSUn8NkKvNHWK3SUe6Lqx4Ou91dpqqOdlk3f9yTgEsERqMRi8Xi/rq4uJi4uLhm1yUmJrbq/U0mU6tfG2ikLoHpauuiqirmmuMAJN80nOgAmjXUUe6Lqx4hIafB6kwGwUFB7bJu13JPcnNzvZYHXNdQUlIS27dvB+DQoUMYjUYiI+XIPtFxWarqsdocdA0LCagk0BE17Q6S8x4aBVyLYMyYMQwfPpw5c+agKAqrVq3SOiQh/Op8bT0AsRF6jSPp+GQdgXcBlwgAnnzySa1DEKLNWG0OALqEyEZz/tb00S8NgkYB1zUkRGdT1+Dssw4NkV9Hf2u6t5DsM9RIPnlCaKzO1SIIll9Hf9M1+S+WFkEj+eQJoTHrhRaBnEHgfzJG4J0kAiE05moRSNeQ/0ki8E4+eUJorK7B1TUkLQJ/a/rslzzQSBKBEBqz2lxdQ/Lr6G/SIvBOPnlCaMzVIgiV6aN+J9NHvZNEIITG6hqkRdBWpEXgnXzyhNBY44Iy+XX0Nxkj8E4+eUJozL2gTAaL/U5aBN5JIhBCY3XSImgzngvKJBG4yCdPCI3JgrK2o/PYYkLDQAKMJAIhNCYLytqO56whyQQu8skTQmOyoKztNN1oTidPPzf5rxBCYzJ9tO14HEwjLQI3+eQJoTGrTRaUtRWPMQIN4wg0kgiE0Ji0CNqOTs4j8Eo+eUJozD1GIIPFfqd4dA1pF0eg8dlRlQ0NDfzsZz/j5MmT2O12nnrqKcaOHcuCBQuoqakhPDwcgBUrVjBixAjeeecdsrKyUBSFJUuWMHnyZCorK1m2bBmVlZWEh4ezbt06YmJifBWiEAHJvbJYBov9ThaUeeezRPCXv/yFsLAwPvroI7777juefvppMjMzAVi9ejVDhgxxX1tYWMi2bdvYsmULVVVVzJs3j1tuuYVNmzYxbtw4Fi9eTHp6Ohs2bGD58uW+ClGIgCRHVbYdRQaLvfLZJ++uu+7i6aefBsBgMFBeXt7itTk5OSQnJ6PX6zEYDPTu3Zv8/Hyys7OZMWMGAFOmTCE7O9tX4QkRsOqkRdBmZEGZdz5rEfGZ7ogAABX/SURBVISEhLj/vWnTJv7jP/7D/fVrr71GWVkZCQkJpKWlYbFYMBgM7u8bDAbMZrNHeWxsLMXFxb4KT4iA5R4slhaB30mLwLtWJYKMjAwyMjI8ypYuXUpycjIffPABhw4d4s033wTggQceYOjQofTr149Vq1bxwQcfNHs/VVWvqKwpk8nUmtCxWq2tfm2gkboEpqutS02dDYATx/Ip0QdWq6Cj3BdXPWprqt1ltbU17bJu/rgnrUoEqamppKamNivPyMjgs88+44033nC3EFxdPQBTp05l27ZtjB8/noKCAnd5UVERRqMRo9GI2WwmKirKXdaSxMTE1oSOyWRq9WsDjdQlMF1tXRocxwGVUcMTA657qKPcF1c9ovZUArUAREVGtMu6Xcs9yc3N9Vrus7ZoYWEhW7Zs4fXXX6dLly6A86/6hQsXUlFRATjHBgYPHsyECRPYtWsX9fX1FBUVUVxczKBBg0hKSiIrKwuAHTt2kJyc7KvwhAhIdodKvd05RqAPkq4hf5N1BN75bIwgIyOD8vJyHnzwQXfZu+++y+zZs1m4cCFhYWHEx8ezdOlSwsLCmD17NvPnz0dRFJ577jl0Oh0LFixg+fLlzJs3j+joaNasWeOr8IQISPXufYZ08mBqAx57Dcl/t5vPEsETTzzBE0880aw8JSWFlJSUZuULFixgwYIFHmURERG88cYbvgpJiIDXOHU0sLqEOioZLPZO2qJCaKhxMZn8KrYFnaws9ko+fUJoSKaOti0ZI/BOPn1CaMg1RiADxW1DJ2MEXsmnTwgNuWYMhUgiaBMyRuCdfPqE0FCD3blwMjhIHkptQTad804SgRAaanA4WwTBcm5im2j67Jc80Eg+fUJoyHahRRAiLYI2IS0C7yQRCKEhd9eQtAjahBxM4518+oTQkM3VNSQtgjYhLQLvJBEIoaEGd9eQ/Cq2BZ3HGIEkAhf59AmhoQb39FF5KLUFWUfgnSQCITRkc7imj8qvYltQpGvIK/n0CaEhd4tA/jxtEx6DxfL0c5P/CiE01LigTH4V24KMEXgnnz4hNOSaNSRjBG1Dxgi8k0QghIZkHUHbkumj3smnTwgN2eyyjqAtyaZz3kkiEEJDDQ5ZR9CWPM8j0DCQAOOzoyr/+Mc/8uqrr9KvXz8AJk2axCOPPMLhw4d57rnnABg6dCjPP/88AO+88w5ZWVkoisKSJUuYPHkylZWVLFu2jMrKSsLDw1m3bh0xMTG+ClGIgOOaNRQsHdZtQictAq98lgjAeT7xihUrPMpefPFF0tLSGDVqFMuWLePzzz9n4MCBbNu2jS1btlBVVcW8efO45ZZb2LRpE+PGjWPx4sWkp6ezYcMGli9f7ssQhQgoNpk11KbC9Y2PPMm9jfz66auvr+f06dOMGjUKgClTppCdnU1OTg7Jycno9XoMBgO9e/cmPz+f7OxsZsyY4XGtEB2ZaxtqWUfQNozRXdz/lhZBI5+2CPbu3cuiRYtoaGhgxYoVxMbGEh0d7f5+bGwsZrOZmJgYDAaDu9xgMGA2m7FYLO7y2NhYiouLfRmeEAFH1hG0LWNUqPvfso6gUasSQUZGBhkZGR5ld955J0uXLuW2227jm2++YcWKFbzzzjse16iq6vX9vJW3dK2LyWS6yqidrFZrq18baKQugelq6lJktgBQainGZKr3Z1it0lHui6se1SVWd1lZaUm7rJs/7kmrEkFqaiqpqaktfv/GG2+ktLSUbt26UV5e7i4vKirCaDRiNBopKCjwWm42m4mKinKXtSQxMbE1oWMymVr92kAjdQlMV1OX6CMHgQp69+xBYuIA/wbWCh3lvrjqEXO+Fv56BoC47t1JTByqcWRX71ruSW5urtdyn7VHN2zYwMcffwzAkSNHMBgM6PV6Bg4cyL59+wDYsWMHycnJTJgwgV27dlFfX09RURHFxcUMGjSIpKQksrKyPK4VoiOTweK21T2ycYxA5dK9Dp2Jz8YIvve977F8+XK2bNlCQ0MDL774IgBpaWk8++yzOBwORo8ezaRJkwCYPXs28+fPR1EUnnvuOXQ6HQsWLGD58uXMmzeP6Oho1qxZ46vwhAhIsg1122q6XqO02qZhJIHFZ4mgR48evP/++83KBw0axIcfftisfMGCBSxYsMCjLCIigjfeeMNXIQkR8FwLymSLibZnqarTOoSAIZ8+ITQkW0xoRxJBI0kEQmhIjqrUjiSCRvLpE0JDrgVlssVE20kZ2QOAO0b01DiSwOHTBWVCiKtjkxZBm1ubOpp7b+zDLYO7ax1KwJBEIISG3C0CGSNoM+H6YKZfH691GAFF/gwRQkM2OZhGBAD59AmhIVlHIAKBJAIhNOReRyBjBEJD8ukTQkONXUPSIhDakUQghIYau4bkV1FoRz59QmiosWtIWgRCO5IIhNCQa4uJEJk1JDQknz4hNNR4Qpm0CIR2JBEIoSFZUCYCgSQCIdrQkaJKqusa3F+7t5iQriGhIfn0CdFGck+UMvNX/2DO23vcZQ2yDbUIAJIIhGgjf/mn86zcA6fPu8tsDtl0TmhPPn1CtBFzZfP9790tAllQJjTks91Hf/vb37J7924AHA4HFouF7du3M3XqVHr06EFQUBAAa9euJT4+npdeeon9+/ejKAppaWmMGjWKs2fP8tRTT2G324mLi2PNmjXo9XpfhSiEpi5OBA6HyoUGAUGSCISGfJYIHnnkER555BEA/vSnP1FSUuL+3oYNG4iIiHB/vXfvXk6cOEF6ejpHjx4lLS2N9PR0XnvtNebNm8cdd9zBL3/5SzIzM5k3b56vQhRCU+aLTsSyORo3nFMUSQRCOz7vGmpoaOCjjz5i/vz5LV6TnZ3N9OnTAUhISOD8+fNUVVWRk5PDtGnTAJgyZQrZ2dm+Dk8IzVzcImiQLahFgPD5J3DHjh3ccssthIaGustWrVrF3LlzWbt2LaqqYrFY6Natm/v7BoMBs9lMbW2tuysoNjYWs9ns6/CE0ExNvR0AfbDz104Wk4lA0aquoYyMDDIyMjzKli5dSnJyMn/4wx94/vnn3eU//vGPSU5OpmvXrjz22GNs37692fupqnpFZU2ZTKbWhI7Vam31awON1CUweauLa08hgGi9gslkorzWmRgU1RGwde8o96Wj1AP8U5dWJYLU1FRSU1ObldfU1HDu3Dn69OnjLrv77rvd/7711ls5cuQIRqMRi8XiLi8uLiYuLo7w8HCsViuhoaEUFRVhNBpbjCExMbE1oWMymVr92kAjdQlM3upyurwWKAAgJCSExMREzp6vBU4Qqg8J2Lp3lPvSUeoB11aX3Nxcr+U+7Ro6fPgwAwcOdH9dWVnJokWLqK+vB+Drr79m8ODBJCUluVsGhw4dwmg0EhkZyaRJk9zlO3bsIDk52ZfhCeFXDofKvuOlVNc72F9Yzg/f28uPfr+PzXtOcMxc5b7O1TpokIPrRYDw6eH1ZrMZg8Hg/joqKopbb72V+++/ny5dunD99dcza9YsFEVh+PDhzJkzB0VRWLVqFeDsXlqxYgXp6en06tXLozUhhFZUVaWqroGo0JBLXrfj30U8vNn5F1eQ7gT2Cw/8v/+7yOM619oBm6wqFgHCp4ng9ttv5/bbb/co++EPf8gPf/jDZtc++eSTzcqMRiMbN270ZUhCXLPNOSd59i8H+e0PxjBrRM8WryuwVLv/7VBV7rmxN30N4bz26Xce17lbBA45nUwEBp8mAiE6olc/OYKqwsOb8yhYndLinP+yGmcX6JSBkfzyBxPpFqFHVVX+9+tCzlVY3de5Wgp2h0wfFYFBPoFCXIYxqnEq9Kem4havK6lyJoLRPULpFuGcBq0oCiP7dPW4zjU24JoYJ2vJhNYkEQhxGcWVjX/N//dfDlJYWuP1utJq54KxrqFBHuWJPaM9vnadQeC4kAlkVbHQmiQCIS6htt6OpaoeRYGh8VGcPW9l8pqdZB082+za0mpni6BrF89E8PDkgdx3Ux9+9/9uBsChOmcYuUgaEFqTRCDEJZwud/71f50hnN/OH8OoPl1xqPDCxybqGuwe15ZeGCO4uEUQrg9mbepobhtqdA8MNzhU6RoSAUMSgRCXUFhWC0CfbuEMjIvkT48mMTQ+itPltXyUc9Lj2tIq74mgKdcuo3aHioqra8gfkQtx5SQRCHEJp9yJIAxwPsiXzRwCwOs786mpdx47abXZqa63ExKkEB7S8pPdtXjM5nC4WwQ6yQRCY5IIhLiEU2XOriFXIgCYcX08o/vGYKmq53+/LgQaxwe6hesvOfjrbhHY1cbBYr9ELsSVk0QgxCUUVzhnAvXo2pgIFEVh9ljnfloHTlcAjYnAEHHpg5RcYwQ2hwP3cLG0CITGJBEIcQmWC4fJdI/0fMAP6O48aOlEiXM1sSsRxEZeJhEENRkjcA0W+yxaIVpHEoEQl2C5MADcPbKLR7krERy/KBEYIjyvu5hrFbFzUZkMFovAIIlAiEsoudAiuPgv/fioULoE67BU1VNptblbDrGX6xoKaj59VAaLhdYkEQjRAodDpcTV5XPRX/o6nUL/2AutAksN5847Vx/HR4dyKY3TRx3ug+slDQitSSIQogXna23YHSrRocHu4yWb6t89HICCkmr3pnI9ul6ua6hpi0C6hkRgkEQgRAsaB4q9P9z7uwaMLdUUVVxZi6DpGIFr1pAibQKhMUkEQrTANVDc0kwgV9eQR4vgconAyxiB5AGhNUkEQrSgpPoyLQL3GEE1Re71Blc2RtBgd7i3mJBzaYTW5GAaIVpgqfQ+Y8jFNYX0n4XlOFSICg0mXH/pX6kQV9eQxzoCyQRCW9IiEKIFLc0YcomP7kJoiM49++dy4wNw0aZzsvuoCBCtTgR79+5l4sSJ7Ny50112+PBh5syZw5w5c9wH0gO888473HfffaSmpvL5558DUFlZyYMPPsjcuXNZtGgR5eXlAOzevZv77ruP+++/n/Xr17c2PCGuWeNiMu8tAkVpnEIKlx8fgMYxAluTriFJBEJrrUoEJ0+eZOPGjYwZM8aj/MUXXyQtLY0tW7ZQVVXF559/TmFhIdu2bePDDz/krbfeYvXq1djtdjZt2sS4ceP46KOPmDlzJhs2bADg5z//Ob/5zW/46KOP+Oqrr8jPz7/2WgrRChW1NgC6hre8SKxpIriSFkGwtxaBdA0JjbUqEcTFxfH6668TFRXlLquvr+f06dOMGjUKgClTppCdnU1OTg7Jycno9XoMBgO9e/cmPz+f7OxsZsyY4XFtYWEhXbt2pWfPnuh0OiZPnkx2drYPqinE1auwOhNBdGjL/f5NdyWdOsx42fcMujBGYGs6fVTygNBYqwaLw8LCmpWVlZURHd14NmtsbCxms5mYmBgMBoO73GAwYDabsVgs7vLY2FiKi4sxm83Nri0sLPQaQ25ubmtCv+bXBhqpi/88fkMwj9/QA6oKyc31/jm8oyfckdrD+YXtDLm5Z4CW6/LICIVHRvSAutNQB3+48NpAq3tTgRzb1ego9QDf1+WyiSAjI4OMjAyPsqVLl5KcnHzJ16mqesXlLV3bkptuuumqrhdCCNGyyyaC1NRUUlNTL/tGBoPBPeALUFRUhNFoxGg0UlBQ4LXcbDYTFRXlUWaxWJpdK4QQwn98Nn00JCSEgQMHsm/fPgB27NhBcnIyEyZMYNeuXdTX11NUVERxcTGDBg0iKSmJrKwsj2v79OlDVVUVp06doqGhgZ07d5KUlOSrEIUQQnihqFfbLwPs2rWLd999l2PHjmEwGIiLi+O9994jPz+fZ599FofDwejRo3n66acBeP/99/m///s/FEXh8ccfZ+LEiVRXV7N8+XLKy8uJjo5mzZo1REVF8fXXX7N27VoAZs6cyaJFi3xS0Zdeeon9+/ejKAppaWnuQe32Iicnh5/85CcMHjwYgCFDhrB48WKeeuop7HY7cXFxrFmzBr3+0tsga+nIkSM8+uijLFy4kPnz53P27Fmv8W/dupVNmzah0+mYPXv2FbVI29rFdVm5ciWHDh0iJiYGgEWLFnHbbbe1i7q88sor5Obm0tDQwEMPPcTIkSPb7X25uC6fffZZu7svtbW1rFy5kpKSEurq6nj00UcZNmyYf++J2gnk5OSoDz74oKqqqpqfn6/Onj1b44iu3p49e9SlS5d6lK1cuVLdtm2bqqqqum7dOvWDDz7QIrQrUl1drc6fP1995pln1Pfff19VVe/xV1dXqzNnzlQrKirU2tpa9c4771TLysq0DL0Zb3VZsWKF+tlnnzW7LtDrkp2drS5evFhVVVUtLS1VJ0+e3G7vi7e6tMf78te//lV9++23VVVV1VOnTqkzZ870+z3pFCuLs7OzmT59OgAJCQmcP3+eqqoqjaO6djk5OUybNg1onIIbqPR6PRs2bPAY8/EW//79+xk5ciRRUVGEhoYyZswY8vLytArbK2918aY91OXmm2/m1VdfBSA6Opra2tp2e1+81cVutze7LtDrkpKSwo9+9CMAzp49S3x8vN/vSadIBBaLhW7durm/dk1hbW/y8/N5+OGHmTt3Ll999RW1tbXuriDXdN1AFRwcTGio54Irb/E3nVYMgXmvvNUFYPPmzTzwwAP89Kc/pbS0tF3UJSgoiPBw57kKmZmZ3Hrrre32vnirS1BQULu8LwBz5szhySefJC0tze/3pFNuOqde/bCI5vr378+SJUu44447KCws5IEHHvD4a6c91qmpluJvL/X6/ve/T0xMDImJibz99tu8/vrr3HjjjR7XBHJdPvnkEzIzM3nvvfeYOXOmu7w93pemdTl48GC7vS9btmzBZDKxfPlyjxj9cU86RYvg4mmpxcXFxMXFaRjR1YuPjyclJQVFUejXrx/du3fn/PnzWK3OffDb41Tb8PDwZvF7u1ftoV4TJ04kMTERgKlTp3LkyJF2U5cvvviCN998kw0bNhAVFdWu78vFdWmP9+XgwYOcPXsWgMTEROx2OxEREX69J50iESQlJbF9+3YADh06hNFoJDIyUuOors7WrVt59913ATCbzZSUlHDvvfe66+WagtueTJo0qVn8o0eP5sCBA1RUVFBdXU1eXh5jx47VONLLW7p0qXsVfE5ODoMHD24XdamsrOSVV17hrbfecs+saa/3xVtd2uN92bdvH++99x7g7Nauqanx+z1p1fTR9mjt2rXs27cPRVFYtWoVw4YN0zqkq1JVVcWTTz5JRUUFNpuNJUuWkJiYyIoVK6irq6NXr16sXr2akJAQrUP16uDBg/ziF7/g9OnTBAcHEx8fz9q1a1m5cmWz+LOysnj33XdRFIX58+dz1113aR2+B291mT9/Pm+//TZhYWGEh4ezevVqYmNjA74u6enp/OY3v2HAgAHuspdffplnnnmm3d0Xb3W599572bx5c7u6L1arlZ/97GecPXsWq9XKkiVLGDFihNffdV/Vo9MkAiGEEN51iq4hIYQQLZNEIIQQnZwkAiGE6OQkEQghRCcniUAIITo5SQRCCNHJSSIQQohOThKBEEJ0cv8f7MYLURGT+24AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylim(-10000, 10000)\n",
    "plt.plot(np.asarray(df['episode_reward_mean']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UiZz8ex3LoDt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DDPG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
